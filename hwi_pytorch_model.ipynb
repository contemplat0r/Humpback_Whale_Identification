{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import importlib\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import skimage\n",
    "from skimage import transform as skimg_transform\n",
    "#from skimage import io as img_io\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, utils, models\n",
    "from torch.utils import data\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "import load_data\n",
    "import model\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'model' from '/home/uldo/work/kaggle/competitions/Humpback_Whale_Identification/code/model.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.style.use('Solarize_Light2')\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "importlib.reload(load_data)\n",
    "importlib.reload(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BATCH_SIZE = 100\n",
    "#BATCH_SIZE = 32\n",
    "#BATCH_SIZE = 200\n",
    "BATCH_SIZE = 128\n",
    "#BATCH_SIZE = 64\n",
    "#BATCH_SIZE = 32\n",
    "#IMAGE_W = 100\n",
    "IMAGE_W = 256\n",
    "#IMAGE_H = 100\n",
    "IMAGE_H = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nclass HWI_ConvNeuralNet(nn.Module):\\n    \\n    def __init__(self):\\n        super(HWI_ConvNeuralNet, self).__init__()\\n        self.conv1 = nn.Sequential(\\n            nn.Conv2d(3, 6, 5, 1, 2),\\n            nn.ReLU(),\\n            nn.MaxPool2d(kernel_size=2)\\n        )\\n        self.conv2 = nn.Sequential(\\n            nn.Conv2d(6, 12, 5, 1, 2),\\n            nn.ReLU(),\\n            nn.MaxPool2d(kernel_size=2)\\n        )\\n        self.drop_out = nn.Dropout()\\n        self.out1 = nn.Linear(int(12 * IMAGE_W/4 * IMAGE_H/4), 900)\\n        self.out2 = nn.Linear(900, 1)\\n        \\n    def forward(self, x):\\n        x = self.conv1(x)\\n        x = self.conv2(x)\\n        x = x.view(x.size(0), -1)\\n        output = self.drop_out(x)\\n        output = self.out1(x)\\n        output = self.out2(output)\\n        #return output, x\\n        return output[:, 0]\\n        #return F.log_softmax(output, dim=1)\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "class HWI_ConvNeuralNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(HWI_ConvNeuralNet, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 6, 5, 1, 2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(6, 12, 5, 1, 2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.drop_out = nn.Dropout()\n",
    "        self.out1 = nn.Linear(int(12 * IMAGE_W/4 * IMAGE_H/4), 900)\n",
    "        self.out2 = nn.Linear(900, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        output = self.drop_out(x)\n",
    "        output = self.out1(x)\n",
    "        output = self.out2(output)\n",
    "        #return output, x\n",
    "        return output[:, 0]\n",
    "        #return F.log_softmax(output, dim=1)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HWI_ConvNeuralNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(HWI_ConvNeuralNet, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 32, 7, padding=1)\n",
    "        self.conv2_bn = nn.BatchNorm2d(32)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)        \n",
    "        self.pool2 = nn.AvgPool2d(3, 3)\n",
    "        \n",
    "        self.fc1 = nn.Linear(64 * 4 * 4 * 16, 1024)\n",
    "        #self.fc1 = nn.Linear(64, 1024)\n",
    "        #self.fc2 = nn.Linear(1024, 5004)\n",
    "        self.fc2 = nn.Linear(1024, 1)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        #print(\"forward, input x.size(): \", x.size())\n",
    "        x = self.pool(F.relu(self.conv2_bn(self.conv1(x))))\n",
    "        #print(\"forward, x.size() after self.pool(F.relu(self.conv2_bn(self.conv1(x)))): \", x.size())\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        #print(\"forward, x.size() after self.pool2(F.relu(self.conv2(x))): \", x.size())\n",
    "        x = x.view(-1, 64 * 4 * 4 * 16)\n",
    "        #print(\"forward, x.size() after x.view(-1, 64 * 4 * 4 * 16): \", x.size())\n",
    "        x = F.relu(self.fc1(x))\n",
    "        #print(\"forward, x.size() after F.relu(self.fc1(x)): \", x.size())\n",
    "        x = self.dropout(x)\n",
    "        #print(\"forward, x.size() after self.dropout(x): \", x.size())\n",
    "        x = self.fc2(x)\n",
    "        #print(\"forward, x.size() after self.fc2(x): \", x.size())\n",
    "        #x = self.fc3(x)\n",
    "        x = self.sigmoid(x)\n",
    "        #print(\"forward, x.size() after self.sigmoid(x): \", x.size())\n",
    "        return x       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HWI_ConvNeuralNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(HWI_ConvNeuralNet, self).__init__()\n",
    "        '''\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 6, 5, 1, 2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(6, 12, 5, 1, 2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.drop_out = nn.Dropout()\n",
    "        self.out1 = nn.Linear(int(12 * IMAGE_W/4 * IMAGE_H/4), 900)\n",
    "        self.out2 = nn.Linear(900, 1)\n",
    "        '''\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=9, stride=2, padding=4)\n",
    "        #self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5, stride=2, padding=2)\n",
    "        #self.fc1 = nn.Linear(int(IMAGE_H * IMAGE_W 131072 x 16), 1024)\n",
    "        #self.fc1 = nn.Linear(524288 * 64, 1024)\n",
    "        self.fc1 = nn.Linear(32768 * 16, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 32)\n",
    "        self.pool = torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "        #forward, input x.size():  torch.Size([64, 3, 256, 256])\n",
    "        #forward, after F.relu(self.conv1(x)) x.size():  torch.Size([64, 32, 128, 128])\n",
    "        #forward, after self.pool(x) x.size():  torch.Size([64, 32, 64, 64])\n",
    "        #forward, after F.relu(self.conv2(x)) x.size():  torch.Size([64, 64, 32, 32])\n",
    "        #forward, after self.pool(x) x.size():  torch.Size([64, 64, 16, 16])\n",
    "        #forward, after x.view(-1, 65536 * 16) x.size():  torch.Size([1, 1048576])\n",
    "        #forward, after F.relu(self.fc1(x)) x.size():  torch.Size([1, 1024])\n",
    "        #forward, after self.dropout x.size():  torch.Size([1, 1024])\n",
    "        #forward, after self.fc2 x.size():  torch.Size([1, 1])\n",
    "        #forward, after self.sigmoid(x) x.size():  torch.Size([1, 1])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        output = self.drop_out(x)\n",
    "        output = self.out1(x)\n",
    "        output = self.out2(output)\n",
    "        #return output, x\n",
    "        return output[:, 0]\n",
    "        '''\n",
    "        #print(\"forward, input x.size(): \", x.size())\n",
    "        \n",
    "        x = F.relu(self.conv1(x))\n",
    "        #print(\"forward, after F.relu(self.conv1(x)) x.size(): \", x.size())\n",
    "        x = self.pool(x)\n",
    "        #print(\"forward, after self.pool(x) x.size(): \", x.size())\n",
    "        x = F.relu(self.conv2(x))\n",
    "        #print(\"forward, after F.relu(self.conv2(x)) x.size(): \", x.size())\n",
    "        x = self.pool(x)     \n",
    "        #print(\"forward, after self.pool(x) x.size(): \", x.size())  \n",
    "        x = x.view(-1, 32768 * 16)\n",
    "        #print(\"forward, after x.view(-1, 65536 * 16) x.size(): \", x.size())\n",
    "        x = F.relu(self.fc1(x))\n",
    "        #print(\"forward, after F.relu(self.fc1(x)) x.size(): \", x.size())\n",
    "        x = self.dropout(x)\n",
    "        #print(\"forward, after self.dropout x.size(): \", x.size())\n",
    "        x = self.fc2(x)\n",
    "        #print(\"forward, after self.fc2 x.size(): \", x.size())\n",
    "        x = self.sigmoid(x)\n",
    "        #print(\"forward, after self.sigmoid(x) x.size(): \", x.size())\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#models.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#models.__dict__['resnet18'](pretrained=False, num_classes=2)\n",
    "#models.__dict__['resnet18'](pretrained=False, num_classes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet18 = models.resnet18(pretrained=True)\n",
    "#resnet18 = models.resnet18(pretrained=False, num_classes=1)\n",
    "#resnet18 = models.resnet18(pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "in_features_num = resnet18.fc.in_features\n",
    "print(in_features_num)\n",
    "out_features_num = resnet18.fc.out_features\n",
    "print(out_features_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resnet18.fc = nn.Linear(features_num, BATCH_SIZE)\n",
    "#resnet18.fc = nn.Linear(BATCH_SIZE, 2048)\n",
    "#resnet18.fc = nn.Linear(2048, BATCH_SIZE)\n",
    "\n",
    "#resnet18.fc = nn.Sigmoid()\n",
    "#nn.Sequential(\n",
    "#    nn.Linear(2048, 128),\n",
    "#    nn.ReLU(inplace=True),\n",
    "#    nn.Linear(128, 2)).to(device)\n",
    "\n",
    "#resnet18.fc = nn.Sigmoid()\n",
    "'''\n",
    "resnet18.fc = nn.Sequential(\n",
    "    nn.Linear(2048, 128),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(128, 2)\n",
    ")\n",
    "'''\n",
    "\n",
    "resnet18.fc = nn.Sequential(\n",
    "    nn.Linear(2048, BATCH_SIZE),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(BATCH_SIZE, 1),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "#RuntimeError: size mismatch, m1: [32 x 2048], m2: [512 x 1000] at /opt/conda/conda-bld/pytorch_1533672544752/work/aten/src/THC/generic/THCTensorMathBlas.cu:249\n",
    "#RuntimeError: size mismatch, m1: [32 x 2048], m2: [512 x 1] at /opt/conda/conda-bld/pytorch_1533672544752/work/aten/src/THC/generic/THCTensorMathBlas.cu:249"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=128, bias=True)\n",
       "    (1): ReLU(inplace)\n",
       "    (2): Linear(in_features=128, out_features=1, bias=True)\n",
       "    (3): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rescale(object):\n",
    "    \"\"\"Rescale the image in a sample to a given size.\n",
    "\n",
    "    Args:\n",
    "        output_size (tuple or int): Desired output size. If tuple, output is\n",
    "            matched to output_size. If int, smaller of image edges is matched\n",
    "            to output_size keeping aspect ratio the same.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, label = sample['image'], sample['label']\n",
    "\n",
    "        orig_height, orig_width = image.shape[:2]\n",
    "        if isinstance(self.output_size, int):\n",
    "            if orig_height > orig_width:\n",
    "                new_height, new_width = self.output_size * orig_height / orig_width, self.output_size\n",
    "            else:\n",
    "                new_height, new_width = self.output_size, self.output_size * orig_width / orig_height\n",
    "        else:\n",
    "            new_height, new_width = self.output_size\n",
    "\n",
    "        new_height, new_width = int(new_height), int(new_width)\n",
    "\n",
    "        img = skimg_transform.resize(image, (new_height, new_width))\n",
    "\n",
    "        return {'image': img, 'label': label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnifyRescale(object):\n",
    "    \n",
    "    def __init__(self, output_size=128):\n",
    "        assert isinstance(output_size, int)\n",
    "        self.output_size = output_size\n",
    "        \n",
    "    def __call__(self, sample):\n",
    "        image, label = sample['image'], sample['label']\n",
    "\n",
    "        img = skimg_transform.resize(image, (self.output_size, self.output_size))\n",
    "\n",
    "        return {'image': img, 'label': label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomCrop(object):\n",
    "    \"\"\"Crop randomly the image in a sample.\n",
    "\n",
    "    Args:\n",
    "        output_size (tuple or int): Desired output size. If int, square crop\n",
    "            is made.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        if isinstance(output_size, int):\n",
    "            self.output_size = (output_size, output_size)\n",
    "        else:\n",
    "            assert len(output_size) == 2\n",
    "            self.output_size = output_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, label = sample['image'], sample['label']\n",
    "\n",
    "        orig_height, orig_width = image.shape[:2]\n",
    "        new_height, new_width = self.output_size\n",
    "\n",
    "        top = np.random.randint(0, orig_height - new_height)\n",
    "        left = np.random.randint(0, orig_width - new_width)\n",
    "\n",
    "        image = image[top: top + new_height, left: left + new_width]\n",
    "\n",
    "        return {'image': image, 'label': label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToTensor(object):\n",
    "    \n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "    def __init__(self, image_size=128):\n",
    "        self.image_size = image_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, label = sample['image'], sample['label']\n",
    "\n",
    "        # swap color axis because\n",
    "        # numpy image: H x W x C\n",
    "        # torch image: C X H X W\n",
    "        \n",
    "        \"\"\" The original code didn't expect gray scale images \"\"\"\n",
    "        \n",
    "        gray_scale_image = torch.zeros(\n",
    "            [self.image_size, self.image_size]\n",
    "        ).shape == image.shape\n",
    "        if gray_scale_image:\n",
    "            image = np.stack((image,) * 3, axis=-1)\n",
    "        \n",
    "        image = image.transpose((2, 0, 1))\n",
    "        return {'image': torch.from_numpy(image), 'label': torch.tensor(label, dtype=torch.uint8)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_whale_batch(sample_batched):\n",
    "    \"\"\"Show whales for a batch of samples.\"\"\"\n",
    "    images_batch = sample_batched['image']\n",
    "    labels_batch = sample_batched['label']\n",
    "    batch_size = len(images_batch)\n",
    "    im_size = images_batch.size(2)\n",
    "\n",
    "    grid = utils.make_grid(images_batch)\n",
    "    plt.imshow(grid.numpy().transpose((1, 2, 0)))\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        plt.title('Batch from dataloader')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(submodule):\n",
    "    if type(submodule) == nn.Linear:\n",
    "        nn.init.xavier_uniform_(submodule.weight)\n",
    "        submodule.bias.data.fill_(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_loaders(dataset, valid_train_ratio=0.6):\n",
    "    dataset_size = len(dataset)\n",
    "    print(\"dataset_size: \", dataset_size)\n",
    "\n",
    "    validation_subset_size = int(dataset_size * (1 - valid_train_ratio))\n",
    "    print(\"validation_subset_size: \", validation_subset_size)\n",
    "\n",
    "    indices = list(range(dataset_size))\n",
    "    validation_indices = np.random.choice(indices, size=validation_subset_size, replace=False)\n",
    "    train_indices = list(set(indices) - set(validation_indices))\n",
    "\n",
    "    train_sampler = SubsetRandomSampler(train_indices)\n",
    "    validation_sampler = SubsetRandomSampler(validation_indices)\n",
    "    \n",
    "    dataset_sizes = {\n",
    "            'train': len(train_indices),\n",
    "            'validation': len(validation_indices)\n",
    "        }\n",
    "\n",
    "    #train_loader = data.DataLoader(dataset, batch_size=BATCH_SIZE, num_workers=1, sampler=train_sampler, pin_memory=True)\n",
    "    train_loader = data.DataLoader(dataset, batch_size=BATCH_SIZE, num_workers=1, sampler=train_sampler)\n",
    "    #validation_loader = data.DataLoader(dataset, batch_size=BATCH_SIZE, num_workers=1, sampler=validation_sampler, pin_memory=True)\n",
    "    validation_loader = data.DataLoader(dataset, batch_size=BATCH_SIZE, num_workers=1, sampler=validation_sampler)\n",
    "    loaders = {\n",
    "            'train': train_loader,\n",
    "            'validation': validation_loader\n",
    "        }\n",
    "\n",
    "    return loaders, dataset_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unfold_batch(batch):\n",
    "    return batch['image'], batch['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_epoch_train(model, data_loader, criterion, optimizer):\n",
    "    \n",
    "    accuracy = 0.0\n",
    "    total_loss = 0.0\n",
    "    correct_predicted_total = 0.0\n",
    "    \n",
    "    for i, data_batch in enumerate(data_loader, 0):\n",
    "        #print(\"one_epoch_model_process, len(data_batch): \", len(data_batch))\n",
    "        #print(\"one_epoch_model_process, type(data_batch): \", type(data_batch))        \n",
    "        \n",
    "        inputs, labels = unfold_batch(data_batch)\n",
    "        #print(\"one_epoch_model_process, inputs.size(): \", inputs.size())\n",
    "        if inputs.size()[0] == BATCH_SIZE:\n",
    "            \n",
    "            #print(\"inputs: \", inputs)\n",
    "            #print(\"labels: \", labels)\n",
    "        \n",
    "            inputs = inputs.to(device, dtype=torch.float)\n",
    "            labels = labels.to(device, dtype=torch.float)\n",
    "            #labels = labels.to(device, dtype=torch.long)\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "            \n",
    "            outputs = model(inputs)\n",
    "\n",
    "            #print(\"outputs.size():\\n\", outputs.size())\n",
    "            #print(\"labels.size():\\n\", labels.size())\n",
    "            #print(\"outputs:\\n\", outputs)\n",
    "            #print(\"outputs[:, 0]:\\n\", outputs[:, 0])\n",
    "            #print(\"labels:\\n\", labels)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "            total_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "            predicted = outputs > 0\n",
    "            #print(\"type(predicted): \", type(predicted))\n",
    "            #print(\"predicted:\\n\", predicted)\n",
    "            ##print(\"predicted.size():\", predicted.size())\n",
    "            ##print(\"predicted:\\n\", predicted)\n",
    "            #total += labels.size(0)\n",
    "            labels = labels.data.byte()\n",
    "            ##print(\"\\nlabels.size():\", labels.size())\n",
    "            ##print(\"labels:\\n\", labels)\n",
    "            #print(\"predicted == labels:\\n\", predicted == labels)\n",
    "            #sum_of_correct_predicted = torch.sum((predicted == labels).all(1))\n",
    "            sum_of_correct_predicted = torch.sum((predicted[0] == labels))\n",
    "            ##print(\"\\nsum_of_correct_predicted.size():\\n\", sum_of_correct_predicted.size())\n",
    "            ##print(\"sum_of_correct_predicted:\\n\", sum_of_correct_predicted)\n",
    "            \n",
    "            item = sum_of_correct_predicted.item()\n",
    "            ##print(\"\\nitem.size(): \", item)\n",
    "            ##print(\"item:\\n\", item)\n",
    "            correct_predicted_total += item\n",
    "        \n",
    "    accuracy = correct_predicted_total\n",
    "    \n",
    "    #epoch_train_loss = total_loss / train_dataset_size\n",
    "    #epoch_train_accuracy = correct_predicted_total / train_dataset_size\n",
    "    return (total_loss, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, validation_loader, criterion):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        correct_predicted_total = 0.0\n",
    "        total_loss = 0.0\n",
    "        #total = 0.0\n",
    "        \n",
    "        for data_batch in validation_loader:\n",
    "            inputs, labels = unfold_batch(data_batch)\n",
    "\n",
    "            inputs = inputs.to(device, dtype=torch.float)\n",
    "            #labels_as_float = labels.to(device, dtype=torch.float)\n",
    "            #labels = labels.to(device, dtype=torch.uint8)\n",
    "            labels = labels.to(device, dtype=torch.float)\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            #loss = criterion(outputs, labels_as_float)\n",
    "            total_loss += loss.item() * inputs.size(0)\n",
    "            \n",
    "            predicted = outputs > 0\n",
    "\n",
    "            #total += labels.size(0)\n",
    "            labels = labels.data.byte()\n",
    "            #sum_of_correct_predicted = torch.sum((predicted == labels).all(1))\n",
    "            sum_of_correct_predicted = torch.sum((predicted == labels))\n",
    "            item = sum_of_correct_predicted.item()\n",
    "\n",
    "            correct_predicted_total += item\n",
    "\n",
    "        #accuracy = correct_predicted_total / total\n",
    "        accuracy = correct_predicted_total\n",
    "        \n",
    "\n",
    "    return (total_loss, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_epoch_validate(model, data_loader, criterion):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        correct_predicted_total = 0.0\n",
    "        total_loss = 0.0\n",
    "\n",
    "        for data_batch in data_loader:\n",
    "            inputs, labels = unfold_batch(data_batch)\n",
    "            if inputs.size()[0] == BATCH_SIZE:\n",
    "\n",
    "                inputs = inputs.to(device, dtype=torch.float)\n",
    "                labels = labels.to(device, dtype=torch.float)\n",
    "                #labels = labels.to(device, dtype=torch.long)\n",
    "                outputs = model(inputs)\n",
    "            \n",
    "                loss = criterion(outputs, labels)\n",
    "                total_loss += loss.item() * inputs.size(0)\n",
    "            \n",
    "                predicted = outputs > 0\n",
    "            \n",
    "                labels = labels.data.byte()\n",
    "                sum_of_correct_predicted = torch.sum((predicted[0] == labels))\n",
    "                item = sum_of_correct_predicted.item()\n",
    "\n",
    "                correct_predicted_total += item\n",
    "\n",
    "        accuracy = correct_predicted_total        \n",
    "\n",
    "    return (total_loss, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_epoch_model_process(model, loader, criterion, optimizer=None):\n",
    "    accuracy = 0.0\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for data_batch in loader:\n",
    "        print(\"one_epoch_model_process, len(data_batch): \", len(data_batch))\n",
    "        print(\"one_epoch_model_process, type(data_batch): \", type(data_batch))\n",
    "        if len(data_batch) == BATCH_SIZE:\n",
    "            inputs, labels = unfold_batch(data_batch)\n",
    "            inputs = inputs.to(device, dtype=torch.float)\n",
    "            labels = labels.to(device, dtype=torch.float)\n",
    "            outputs = model(inputs)[:, 0]\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            if optimizer:\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            total_loss += loss.item() * inputs.size(0)\n",
    "            \n",
    "            predicted = outputs > 0\n",
    "\n",
    "            labels = labels.data.byte()\n",
    "            #torch_sum_of_correct_predicted = torch.sum((predicted == labels).all(1))\n",
    "            torch_sum_of_correct_predicted = torch.sum((predicted == labels))\n",
    "            correct_predicted = torch_sum_of_correct_predicted.item()\n",
    "\n",
    "    accuracy += correct_predicted        \n",
    "\n",
    "    return (total_loss, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(num_of_epoch, model, dataset_loaders, dataset_sizes, criterion, optimizer):\n",
    "    torch.cuda.empty_cache()\n",
    "    since = time.time()\n",
    "    \n",
    "    train_loader = dataset_loaders['train']\n",
    "    validation_loader = dataset_loaders['validation']\n",
    "    train_dataset_size = dataset_sizes['train']\n",
    "    validation_dataset_size = dataset_sizes['validation']\n",
    "    \n",
    "    best_model_accuracy = 0.0\n",
    "    best_model_weights = model.state_dict()\n",
    "    \n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    validation_losses = []\n",
    "    validation_accuracies = []\n",
    "    \n",
    "    for epoch in range(num_of_epoch):\n",
    "        \n",
    "        train_loss, train_accuracy = one_epoch_train(model, train_loader, criterion, optimizer)\n",
    "        train_losses.append(train_loss / train_dataset_size)\n",
    "        train_accuracies.append(train_accuracy / train_dataset_size)\n",
    "        \n",
    "        validation_loss, validation_accuracy = one_epoch_validate(model, validation_loader, criterion)\n",
    "        validation_losses.append(validation_loss / validation_dataset_size)\n",
    "        validation_accuracies.append(validation_accuracy / validation_dataset_size)\n",
    "        \n",
    "        if validation_accuracy > best_model_accuracy:\n",
    "            best_model_accuracy = validation_accuracy\n",
    "            best_model_weights = model.state_dict()\n",
    "        \n",
    "        print(\"Epoch {}: train loss {}, train accuracy\"\n",
    "          \" {}, validation loss {}, validation accuracy {}\".format(\n",
    "              epoch + 1,\n",
    "              train_loss / train_dataset_size,\n",
    "              train_accuracy / train_dataset_size,\n",
    "              validation_loss / validation_dataset_size,\n",
    "              validation_accuracy / validation_dataset_size\n",
    "            )\n",
    "        )\n",
    "    print(\"Finished Training\")\n",
    "    time_elapsed = time.time() - since\n",
    "    print(\n",
    "            'Training complete in {:.0f}m {:.0f}s'.format(\n",
    "            time_elapsed // 60, time_elapsed % 60\n",
    "        )\n",
    "    )\n",
    "    print(\"Best model accuracy: \", best_model_accuracy / validation_dataset_size)\n",
    "    model.load_state_dict(best_model_weights)\n",
    "    return train_losses, validation_losses, train_accuracies, validation_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(model, batch):\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    #inputs = batch\n",
    "    #inputs = inputs.to(device, dtype=torch.float)\n",
    "    inputs = batch.to(device, dtype=torch.float)\n",
    "    outputs = model(inputs)\n",
    "    #return outputs[0].cpu()\n",
    "    return outputs.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, full=True, name='model'):\n",
    "    if not full:\n",
    "        torch.save(model.state_dict(), '{}_params.pkl'.format(name))\n",
    "    else:\n",
    "        torch.save(model, '{}.pkl'.format(name))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restore_model(name='model'):\n",
    "    return torch.load('{}.pkl'.format(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = load_data.load_text_data('../input/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_two_classes = train_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_two_classes.loc[train_df_two_classes['Id'] != 'new_whale', 'Id'] = 'not_new_whale'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000e88ab.jpg</td>\n",
       "      <td>not_new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0001f9222.jpg</td>\n",
       "      <td>not_new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00029d126.jpg</td>\n",
       "      <td>not_new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00050a15a.jpg</td>\n",
       "      <td>new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0005c1ef8.jpg</td>\n",
       "      <td>new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0006e997e.jpg</td>\n",
       "      <td>new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>000a6daec.jpg</td>\n",
       "      <td>not_new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>000f0f2bf.jpg</td>\n",
       "      <td>new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0016b897a.jpg</td>\n",
       "      <td>not_new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>001c1ac5f.jpg</td>\n",
       "      <td>not_new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>001cae55b.jpg</td>\n",
       "      <td>not_new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>001d7450c.jpg</td>\n",
       "      <td>new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>00200e115.jpg</td>\n",
       "      <td>new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>00245a598.jpg</td>\n",
       "      <td>new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>002b4615d.jpg</td>\n",
       "      <td>new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>002f99f01.jpg</td>\n",
       "      <td>new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>00355ff28.jpg</td>\n",
       "      <td>not_new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>00357e37a.jpg</td>\n",
       "      <td>not_new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>003795857.jpg</td>\n",
       "      <td>new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0041880bf.jpg</td>\n",
       "      <td>new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0043da555.jpg</td>\n",
       "      <td>new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>00442c882.jpg</td>\n",
       "      <td>not_new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>00464ff65.jpg</td>\n",
       "      <td>new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>004775679.jpg</td>\n",
       "      <td>not_new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>004ae9e26.jpg</td>\n",
       "      <td>new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>004c0f43b.jpg</td>\n",
       "      <td>new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>004e8ad5b.jpg</td>\n",
       "      <td>not_new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>004f87702.jpg</td>\n",
       "      <td>not_new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0050ef29d.jpg</td>\n",
       "      <td>not_new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>00514c876.jpg</td>\n",
       "      <td>not_new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0052ce2f5.jpg</td>\n",
       "      <td>not_new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>00537ec91.jpg</td>\n",
       "      <td>not_new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>00570db6b.jpg</td>\n",
       "      <td>not_new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>005ce3100.jpg</td>\n",
       "      <td>new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>00600ce17.jpg</td>\n",
       "      <td>new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>006017ddf.jpg</td>\n",
       "      <td>not_new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0060f764a.jpg</td>\n",
       "      <td>not_new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>006500b3d.jpg</td>\n",
       "      <td>not_new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>006506edf.jpg</td>\n",
       "      <td>new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0067b3a20.jpg</td>\n",
       "      <td>not_new_whale</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Image             Id\n",
       "0   0000e88ab.jpg  not_new_whale\n",
       "1   0001f9222.jpg  not_new_whale\n",
       "2   00029d126.jpg  not_new_whale\n",
       "3   00050a15a.jpg      new_whale\n",
       "4   0005c1ef8.jpg      new_whale\n",
       "5   0006e997e.jpg      new_whale\n",
       "6   000a6daec.jpg  not_new_whale\n",
       "7   000f0f2bf.jpg      new_whale\n",
       "8   0016b897a.jpg  not_new_whale\n",
       "9   001c1ac5f.jpg  not_new_whale\n",
       "10  001cae55b.jpg  not_new_whale\n",
       "11  001d7450c.jpg      new_whale\n",
       "12  00200e115.jpg      new_whale\n",
       "13  00245a598.jpg      new_whale\n",
       "14  002b4615d.jpg      new_whale\n",
       "15  002f99f01.jpg      new_whale\n",
       "16  00355ff28.jpg  not_new_whale\n",
       "17  00357e37a.jpg  not_new_whale\n",
       "18  003795857.jpg      new_whale\n",
       "19  0041880bf.jpg      new_whale\n",
       "20  0043da555.jpg      new_whale\n",
       "21  00442c882.jpg  not_new_whale\n",
       "22  00464ff65.jpg      new_whale\n",
       "23  004775679.jpg  not_new_whale\n",
       "24  004ae9e26.jpg      new_whale\n",
       "25  004c0f43b.jpg      new_whale\n",
       "26  004e8ad5b.jpg  not_new_whale\n",
       "27  004f87702.jpg  not_new_whale\n",
       "28  0050ef29d.jpg  not_new_whale\n",
       "29  00514c876.jpg  not_new_whale\n",
       "30  0052ce2f5.jpg  not_new_whale\n",
       "31  00537ec91.jpg  not_new_whale\n",
       "32  00570db6b.jpg  not_new_whale\n",
       "33  005ce3100.jpg      new_whale\n",
       "34  00600ce17.jpg      new_whale\n",
       "35  006017ddf.jpg  not_new_whale\n",
       "36  0060f764a.jpg  not_new_whale\n",
       "37  006500b3d.jpg  not_new_whale\n",
       "38  006506edf.jpg      new_whale\n",
       "39  0067b3a20.jpg  not_new_whale"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_two_classes.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimage_size = 128\\ndataset = load_data.HumpbackWhalesDataset(\\n    train_df_two_classes,\\n    #train_df,\\n    #transform=load_data.transforms.ToTensor()\\n    #transform=ToTensor()\\n    transform=transforms.Compose(\\n        [\\n            #Rescale(int(image_size*1.25)),\\n            Rescale(int(image_size)),\\n            #RandomCrop(image_size),\\n            UnifyRescale(int(image_size)),\\n            ToTensor()\\n        ]\\n    )\\n)\\n'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "image_size = 128\n",
    "dataset = load_data.HumpbackWhalesDataset(\n",
    "    train_df_two_classes,\n",
    "    #train_df,\n",
    "    #transform=load_data.transforms.ToTensor()\n",
    "    #transform=ToTensor()\n",
    "    transform=transforms.Compose(\n",
    "        [\n",
    "            #Rescale(int(image_size*1.25)),\n",
    "            Rescale(int(image_size)),\n",
    "            #RandomCrop(image_size),\n",
    "            UnifyRescale(int(image_size)),\n",
    "            ToTensor()\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image_size = 128\n",
    "#image_size = 100\n",
    "dataset = load_data.HumpbackWhalesDataset(\n",
    "    train_df_two_classes,\n",
    "    #train_df,\n",
    "    #transform=load_data.transforms.ToTensor()\n",
    "    #transform=ToTensor()\n",
    "    transform=transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize((IMAGE_W, IMAGE_H)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225]\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_size:  25361\n",
      "validation_subset_size:  10144\n"
     ]
    }
   ],
   "source": [
    "dataset_loaders, dataset_sizes = prepare_loaders(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = dataset_loaders['train']\n",
    "validation_loader = dataset_loaders['validation']\n",
    "train_dataset_size = dataset_sizes['train']\n",
    "validation_dataset_size = dataset_sizes['validation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15217\n",
      "10144\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset_size)\n",
    "print(validation_dataset_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7f852b8a3c18>\n"
     ]
    }
   ],
   "source": [
    "print(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = iter(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.utils.data.dataloader._DataLoaderIter'>\n"
     ]
    }
   ],
   "source": [
    "print(type(train_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image': tensor([[[[ 2.0948,  2.0948,  2.0948,  ...,  2.0948,  2.0948,  2.0948],\n",
      "          [ 2.2318,  2.2318,  2.2318,  ...,  2.2318,  2.2318,  2.2318],\n",
      "          [ 2.2318,  2.2318,  2.2318,  ...,  2.2318,  2.2318,  2.2318],\n",
      "          ...,\n",
      "          [ 2.2318,  2.2318,  2.2318,  ...,  2.2318,  2.2318,  2.2318],\n",
      "          [ 2.2318,  2.2318,  2.2318,  ...,  2.2318,  2.2318,  2.2318],\n",
      "          [ 2.0948,  2.0948,  2.0948,  ...,  2.0948,  2.0948,  2.0948]],\n",
      "\n",
      "         [[ 2.2710,  2.2710,  2.2710,  ...,  2.2710,  2.2710,  2.2710],\n",
      "          [ 2.4111,  2.4111,  2.4111,  ...,  2.4111,  2.4111,  2.4111],\n",
      "          [ 2.4111,  2.4111,  2.4111,  ...,  2.4111,  2.4111,  2.4111],\n",
      "          ...,\n",
      "          [ 2.4111,  2.4111,  2.4111,  ...,  2.4111,  2.4111,  2.4111],\n",
      "          [ 2.4111,  2.4111,  2.4111,  ...,  2.4111,  2.4111,  2.4111],\n",
      "          [ 2.2710,  2.2710,  2.2710,  ...,  2.2710,  2.2710,  2.2710]],\n",
      "\n",
      "         [[ 2.4831,  2.4831,  2.4831,  ...,  2.4831,  2.4831,  2.4831],\n",
      "          [ 2.6226,  2.6226,  2.6226,  ...,  2.6226,  2.6226,  2.6226],\n",
      "          [ 2.6226,  2.6226,  2.6226,  ...,  2.6226,  2.6226,  2.6226],\n",
      "          ...,\n",
      "          [ 2.6226,  2.6226,  2.6226,  ...,  2.6226,  2.6226,  2.6226],\n",
      "          [ 2.6226,  2.6226,  2.6226,  ...,  2.6226,  2.6226,  2.6226],\n",
      "          [ 2.4831,  2.4831,  2.4831,  ...,  2.4831,  2.4831,  2.4831]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2111,  0.2624,  0.3481,  ...,  0.4337,  0.4166,  0.4337],\n",
      "          [ 0.3994,  0.4337,  0.4508,  ...,  0.5536,  0.5193,  0.4679],\n",
      "          [ 0.7419,  0.7591,  0.7762,  ...,  0.5193,  0.4851,  0.4679],\n",
      "          ...,\n",
      "          [ 0.5878,  0.7591,  0.7933,  ...,  1.1358,  1.7523,  1.9064],\n",
      "          [ 0.3652,  0.5536,  0.5536,  ...,  0.6221,  1.1529,  1.5982],\n",
      "          [ 0.3652,  0.5022,  0.5536,  ...,  0.5364,  0.8618,  0.9988]],\n",
      "\n",
      "         [[ 0.3452,  0.3978,  0.4853,  ...,  0.5728,  0.5553,  0.5728],\n",
      "          [ 0.5378,  0.5728,  0.5903,  ...,  0.6954,  0.6604,  0.6078],\n",
      "          [ 0.8880,  0.9055,  0.9230,  ...,  0.6604,  0.6254,  0.6078],\n",
      "          ...,\n",
      "          [ 0.7304,  0.9055,  0.9405,  ...,  1.2906,  1.9209,  2.0784],\n",
      "          [ 0.5028,  0.6954,  0.6954,  ...,  0.7654,  1.3081,  1.7633],\n",
      "          [ 0.5028,  0.6429,  0.6954,  ...,  0.6779,  1.0105,  1.1506]],\n",
      "\n",
      "         [[ 0.5659,  0.6182,  0.7054,  ...,  0.7925,  0.7751,  0.7925],\n",
      "          [ 0.7576,  0.7925,  0.8099,  ...,  0.9145,  0.8797,  0.8274],\n",
      "          [ 1.1062,  1.1237,  1.1411,  ...,  0.8797,  0.8448,  0.8274],\n",
      "          ...,\n",
      "          [ 0.9494,  1.1237,  1.1585,  ...,  1.5071,  2.1346,  2.2914],\n",
      "          [ 0.7228,  0.9145,  0.9145,  ...,  0.9842,  1.5245,  1.9777],\n",
      "          [ 0.7228,  0.8622,  0.9145,  ...,  0.8971,  1.2282,  1.3677]]],\n",
      "\n",
      "\n",
      "        [[[-0.4054, -0.3712, -0.4397,  ..., -0.7137, -0.6794, -0.6794],\n",
      "          [-0.3883, -0.3541, -0.3369,  ..., -0.7137, -0.6965, -0.7137],\n",
      "          [-0.4397, -0.3369, -0.3198,  ..., -0.7822, -0.7137, -0.6623],\n",
      "          ...,\n",
      "          [-0.3198, -0.3541, -0.3883,  ...,  0.2624,  0.2967,  0.3994],\n",
      "          [-0.2684, -0.3027, -0.3541,  ...,  0.3994,  0.3823,  0.4508],\n",
      "          [-0.2856, -0.2856, -0.3712,  ...,  0.2967,  0.2796,  0.3481]],\n",
      "\n",
      "         [[ 0.1001,  0.1176,  0.0301,  ..., -0.2850, -0.2675, -0.2850],\n",
      "          [ 0.1352,  0.1352,  0.1176,  ..., -0.2675, -0.2850, -0.3200],\n",
      "          [ 0.0826,  0.1527,  0.1527,  ..., -0.3200, -0.3200, -0.2675],\n",
      "          ...,\n",
      "          [ 0.0826,  0.0301,  0.0301,  ...,  0.6604,  0.6954,  0.7829],\n",
      "          [ 0.1527,  0.1001,  0.0651,  ...,  0.8004,  0.7479,  0.8179],\n",
      "          [ 0.1527,  0.1176,  0.0476,  ...,  0.6954,  0.6954,  0.7304]],\n",
      "\n",
      "         [[ 0.8797,  0.8622,  0.7576,  ...,  0.3916,  0.4091,  0.3916],\n",
      "          [ 0.8971,  0.8797,  0.8622,  ...,  0.3916,  0.3916,  0.3568],\n",
      "          [ 0.8448,  0.8971,  0.8971,  ...,  0.3568,  0.3568,  0.3916],\n",
      "          ...,\n",
      "          [ 0.7228,  0.6705,  0.6705,  ...,  1.0888,  1.1585,  1.2631],\n",
      "          [ 0.8099,  0.7576,  0.7228,  ...,  1.2457,  1.2631,  1.3502],\n",
      "          [ 0.7925,  0.7751,  0.6879,  ...,  1.2457,  1.2631,  1.2980]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 1.6495,  1.6324,  1.5982,  ...,  0.8104,  0.8276,  0.8961],\n",
      "          [ 1.5297,  1.4954,  1.4783,  ...,  0.9474,  0.9817,  1.0502],\n",
      "          [ 1.3584,  1.3584,  1.3413,  ...,  1.0844,  1.1187,  1.1529],\n",
      "          ...,\n",
      "          [ 0.9817,  0.9646,  0.9132,  ...,  0.7248,  0.7419,  0.7591],\n",
      "          [ 0.9988,  0.9817,  0.9303,  ...,  0.7933,  0.7933,  0.8447],\n",
      "          [ 1.0331,  1.0159,  0.9646,  ...,  0.9132,  0.8618,  0.9303]],\n",
      "\n",
      "         [[ 1.8158,  1.7983,  1.7633,  ...,  0.9580,  0.9755,  1.0455],\n",
      "          [ 1.6933,  1.6583,  1.6408,  ...,  1.0980,  1.1331,  1.2031],\n",
      "          [ 1.5182,  1.5182,  1.5007,  ...,  1.2381,  1.2731,  1.3081],\n",
      "          ...,\n",
      "          [ 1.1331,  1.1155,  1.0630,  ...,  0.8704,  0.8880,  0.9055],\n",
      "          [ 1.1506,  1.1331,  1.0805,  ...,  0.9405,  0.9405,  0.9930],\n",
      "          [ 1.1856,  1.1681,  1.1155,  ...,  1.0630,  1.0105,  1.0805]],\n",
      "\n",
      "         [[ 2.0300,  2.0125,  1.9777,  ...,  1.1759,  1.1934,  1.2631],\n",
      "          [ 1.9080,  1.8731,  1.8557,  ...,  1.3154,  1.3502,  1.4200],\n",
      "          [ 1.7337,  1.7337,  1.7163,  ...,  1.4548,  1.4897,  1.5245],\n",
      "          ...,\n",
      "          [ 1.3502,  1.3328,  1.2805,  ...,  1.0888,  1.1062,  1.1237],\n",
      "          [ 1.3677,  1.3502,  1.2980,  ...,  1.1585,  1.1585,  1.2108],\n",
      "          [ 1.4025,  1.3851,  1.3328,  ...,  1.2805,  1.2282,  1.2980]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2043,  1.2385,  1.2214,  ...,  0.6906,  0.7248,  0.7762],\n",
      "          [ 1.2043,  1.2728,  1.2557,  ...,  0.7077,  0.7762,  0.7933],\n",
      "          [ 1.1700,  1.2385,  1.2385,  ...,  0.8104,  0.8104,  0.8276],\n",
      "          ...,\n",
      "          [ 1.2385,  1.2043,  1.1700,  ...,  1.2043,  1.2043,  1.1700],\n",
      "          [ 1.2728,  1.2385,  1.1872,  ...,  1.2043,  1.1872,  1.1529],\n",
      "          [ 1.3070,  1.2899,  1.2214,  ...,  1.1872,  1.1872,  1.1358]],\n",
      "\n",
      "         [[ 1.3606,  1.3957,  1.3782,  ...,  0.8354,  0.8704,  0.9230],\n",
      "          [ 1.3606,  1.4307,  1.4132,  ...,  0.8529,  0.9230,  0.9405],\n",
      "          [ 1.3256,  1.3957,  1.3957,  ...,  0.9580,  0.9580,  0.9755],\n",
      "          ...,\n",
      "          [ 1.3957,  1.3606,  1.3256,  ...,  1.3606,  1.3606,  1.3256],\n",
      "          [ 1.4307,  1.3957,  1.3431,  ...,  1.3606,  1.3431,  1.3081],\n",
      "          [ 1.4657,  1.4482,  1.3782,  ...,  1.3431,  1.3431,  1.2906]],\n",
      "\n",
      "         [[ 1.5768,  1.6117,  1.5942,  ...,  1.0539,  1.0888,  1.1411],\n",
      "          [ 1.5768,  1.6465,  1.6291,  ...,  1.0714,  1.1411,  1.1585],\n",
      "          [ 1.5420,  1.6117,  1.6117,  ...,  1.1759,  1.1759,  1.1934],\n",
      "          ...,\n",
      "          [ 1.6117,  1.5768,  1.5420,  ...,  1.5768,  1.5768,  1.5420],\n",
      "          [ 1.6465,  1.6117,  1.5594,  ...,  1.5768,  1.5594,  1.5245],\n",
      "          [ 1.6814,  1.6640,  1.5942,  ...,  1.5594,  1.5594,  1.5071]]],\n",
      "\n",
      "\n",
      "        [[[-0.7137, -0.6109, -0.5424,  ..., -0.7479, -1.0733, -1.2788],\n",
      "          [-0.6794, -0.5938, -0.5596,  ..., -0.9705, -1.2617, -1.2959],\n",
      "          [-0.6623, -0.5938, -0.5938,  ..., -1.1247, -1.3473, -1.1932],\n",
      "          ...,\n",
      "          [-1.0562, -1.0390, -1.0733,  ...,  2.2318,  2.2318,  2.2318],\n",
      "          [-1.1075, -1.0733, -1.0904,  ...,  2.2318,  2.2318,  2.2318],\n",
      "          [-1.1589, -1.1418, -1.0904,  ...,  2.2318,  2.2318,  2.2318]],\n",
      "\n",
      "         [[-0.0574,  0.0826,  0.1702,  ..., -0.0924, -0.4426, -0.6877],\n",
      "          [ 0.0126,  0.1176,  0.1527,  ..., -0.3200, -0.6352, -0.7052],\n",
      "          [ 0.0476,  0.1176,  0.1176,  ..., -0.4951, -0.7402, -0.6001],\n",
      "          ...,\n",
      "          [-0.4076, -0.4076, -0.4251,  ...,  2.4111,  2.4111,  2.4111],\n",
      "          [-0.4776, -0.4426, -0.4601,  ...,  2.4111,  2.4111,  2.4111],\n",
      "          [-0.5301, -0.5126, -0.4601,  ...,  2.4111,  2.4111,  2.4111]],\n",
      "\n",
      "         [[ 0.7751,  0.9494,  1.0365,  ...,  0.6531,  0.1999, -0.1138],\n",
      "          [ 0.8448,  0.9842,  1.0191,  ...,  0.3916, -0.0267, -0.1138],\n",
      "          [ 0.8971,  0.9842,  0.9842,  ...,  0.1476, -0.1661,  0.0256],\n",
      "          ...,\n",
      "          [ 0.3219,  0.3219,  0.2871,  ...,  2.6226,  2.6226,  2.6226],\n",
      "          [ 0.2348,  0.2696,  0.2522,  ...,  2.6226,  2.6226,  2.6226],\n",
      "          [ 0.1476,  0.1651,  0.2173,  ...,  2.6226,  2.6226,  2.6226]]]]), 'label': tensor([0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
      "        1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
      "        1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1,\n",
      "        0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
      "        0, 0, 1, 0, 0, 0, 0, 0])}\n"
     ]
    }
   ],
   "source": [
    "#images, labels = train_iter.next()\n",
    "sample = train_iter.next()\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfor i_batch, sample_batched in enumerate(train_loader):\\n    print(i_batch, sample_batched['image'].size(),\\n          sample_batched['label'])\\n    # observe 4th batch and stop.\\n    if i_batch == 0:\\n        plt.figure(figsize=(24, 24))\\n        show_whale_batch(sample_batched)\\n        plt.axis('off')\\n        #plt.ioff()\\n        plt.show()\\n        break\\n\""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "for i_batch, sample_batched in enumerate(train_loader):\n",
    "    print(i_batch, sample_batched['image'].size(),\n",
    "          sample_batched['label'])\n",
    "    # observe 4th batch and stop.\n",
    "    if i_batch == 0:\n",
    "        plt.figure(figsize=(24, 24))\n",
    "        show_whale_batch(sample_batched)\n",
    "        plt.axis('off')\n",
    "        #plt.ioff()\n",
    "        plt.show()\n",
    "        break\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'not_new_whale': 0, 'new_whale': 1}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hwi_conv_neural_net = HWI_ConvNeuralNet()\n",
    "#hwi_conv_neural_net.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hwi_conv_neural_net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#criterion = nn.BCEWithLogitsLoss(reduction='sum')\n",
    "#criterion = nn.BCEWithLogitsLoss()\n",
    "#criterion = nn.BCELoss()\n",
    "#optimizer = optim.Adam(hwi_conv_neural_net.parameters(), lr=0.001, betas=(0.9, 0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_epoch = 12\n",
    "#train_losses = []\n",
    "#train_accuracies = []\n",
    "#validation_losses = []\n",
    "#validation_accuracies = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntorch.cuda.empty_cache()\\nsince = time.time()\\nfor epoch in range(num_of_epoch):\\n    epoch_train_accuracy = 0.0\\n    epoch_train_loss = 0.0\\n    correct_predicted_total = 0.0\\n    train_loss = 0.0\\n    #total_loss = 0.0\\n    #total = 0.0\\n    for i, data_batch in enumerate(train_loader, 0):\\n        \\n        inputs = data_batch[\\'image\\']\\n        labels = data_batch[\\'label\\']\\n        print(\"inputs: \", inputs)\\n        print(\"labels: \", labels)\\n        inputs = inputs.to(device, dtype=torch.float)\\n        labels = labels.to(device, dtype=torch.float)\\n        optimizer.zero_grad()\\n        \\n        outputs = hwi_conv_neural_net(inputs)\\n\\n        print(\"outputs.size():\\n\", outputs.size())\\n        print(\"labels.size():\\n\", labels.size())\\n        print(\"outputs:\\n\", outputs)\\n        #print(\"outputs[:, 0]:\\n\", outputs[:, 0])\\n        print(\"labels:\\n\", labels)\\n        loss = criterion(outputs, labels)\\n        loss.backward()\\n        optimizer.step()\\n        \\n        train_loss += loss.item() * inputs.size(0)\\n        \\n        predicted = outputs > 0\\n        print(\"type(predicted): \", type(predicted))\\n        print(\"predicted:\\n\", predicted)\\n\\n        #total += labels.size(0)\\n        labels = labels.data.byte()\\n        print(\"predicted == labels:\\n\", predicted == labels)\\n        #sum_of_correct_predicted = torch.sum((predicted == labels).all(1))\\n        sum_of_correct_predicted = torch.sum((predicted == labels))\\n        item = sum_of_correct_predicted.item()\\n        correct_predicted_total += item\\n        \\n    epoch_train_loss = train_loss / train_dataset_size\\n    epoch_train_accuracy = correct_predicted_total / train_dataset_size\\n    \\n    validation_loss, validation_accuracy = validate(hwi_conv_neural_net, validation_loader, criterion)\\n    \\n    epoch_validation_loss = validation_loss / validation_dataset_size\\n    epoch_validation_accuracy = validation_accuracy / validation_dataset_size\\n    \\n    print(\"Epoch {}: train loss {}, train accuracy\"\\n          \" {}, validation loss {}, validation accuracy {}\".format(\\n              epoch + 1,\\n              epoch_train_loss,\\n              epoch_train_accuracy,\\n              epoch_validation_loss,\\n              epoch_validation_accuracy\\n        )\\n    )\\n    train_losses.append(epoch_train_loss)\\n    train_accuracies.append(epoch_train_accuracy)\\n    validation_losses.append(epoch_validation_loss)\\n    validation_accuracies.append(epoch_validation_accuracy)\\n            \\nprint(\"Finished Training\")\\ntime_elapsed = time.time() - since\\nprint(\\n    \\'Training complete in {:.0f}m {:.0f}s\\'.format(\\n        time_elapsed // 60, time_elapsed % 60\\n    )\\n)\\n'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "torch.cuda.empty_cache()\n",
    "since = time.time()\n",
    "for epoch in range(num_of_epoch):\n",
    "    epoch_train_accuracy = 0.0\n",
    "    epoch_train_loss = 0.0\n",
    "    correct_predicted_total = 0.0\n",
    "    train_loss = 0.0\n",
    "    #total_loss = 0.0\n",
    "    #total = 0.0\n",
    "    for i, data_batch in enumerate(train_loader, 0):\n",
    "        \n",
    "        inputs = data_batch['image']\n",
    "        labels = data_batch['label']\n",
    "        print(\"inputs: \", inputs)\n",
    "        print(\"labels: \", labels)\n",
    "        inputs = inputs.to(device, dtype=torch.float)\n",
    "        labels = labels.to(device, dtype=torch.float)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = hwi_conv_neural_net(inputs)\n",
    "\n",
    "        print(\"outputs.size():\\n\", outputs.size())\n",
    "        print(\"labels.size():\\n\", labels.size())\n",
    "        print(\"outputs:\\n\", outputs)\n",
    "        #print(\"outputs[:, 0]:\\n\", outputs[:, 0])\n",
    "        print(\"labels:\\n\", labels)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "        predicted = outputs > 0\n",
    "        print(\"type(predicted): \", type(predicted))\n",
    "        print(\"predicted:\\n\", predicted)\n",
    "\n",
    "        #total += labels.size(0)\n",
    "        labels = labels.data.byte()\n",
    "        print(\"predicted == labels:\\n\", predicted == labels)\n",
    "        #sum_of_correct_predicted = torch.sum((predicted == labels).all(1))\n",
    "        sum_of_correct_predicted = torch.sum((predicted == labels))\n",
    "        item = sum_of_correct_predicted.item()\n",
    "        correct_predicted_total += item\n",
    "        \n",
    "    epoch_train_loss = train_loss / train_dataset_size\n",
    "    epoch_train_accuracy = correct_predicted_total / train_dataset_size\n",
    "    \n",
    "    validation_loss, validation_accuracy = validate(hwi_conv_neural_net, validation_loader, criterion)\n",
    "    \n",
    "    epoch_validation_loss = validation_loss / validation_dataset_size\n",
    "    epoch_validation_accuracy = validation_accuracy / validation_dataset_size\n",
    "    \n",
    "    print(\"Epoch {}: train loss {}, train accuracy\"\n",
    "          \" {}, validation loss {}, validation accuracy {}\".format(\n",
    "              epoch + 1,\n",
    "              epoch_train_loss,\n",
    "              epoch_train_accuracy,\n",
    "              epoch_validation_loss,\n",
    "              epoch_validation_accuracy\n",
    "        )\n",
    "    )\n",
    "    train_losses.append(epoch_train_loss)\n",
    "    train_accuracies.append(epoch_train_accuracy)\n",
    "    validation_losses.append(epoch_validation_loss)\n",
    "    validation_accuracies.append(epoch_validation_accuracy)\n",
    "            \n",
    "print(\"Finished Training\")\n",
    "time_elapsed = time.time() - since\n",
    "print(\n",
    "    'Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60\n",
    "    )\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resnet18 = models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features_num = resnet18.fc.in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resnet18.fc = nn.Linear(features_num, BATCH_SIZE)\n",
    "#resnet18.fc = nn.Linear(BATCH_SIZE, 2048)\n",
    "#resnet18.fc = nn.Linear(2048, BATCH_SIZE)\n",
    "#resnet18.fc = nn.Sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=128, bias=True)\n",
       "    (1): ReLU(inplace)\n",
       "    (2): Linear(in_features=128, out_features=1, bias=True)\n",
       "    (3): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet18.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resnet18.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resnet18.state_dict()['conv1.weight'].size()\n",
    "#resnet18.state_dict()['fc.weight'].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = optim.SGD(resnet18.parameters(), lr=learning_rate, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "#criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(resnet18.parameters(), lr=0.001, betas=(0.9, 0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train loss 0.5779390118865857, train accuracy 0.3756982322402576, validation loss 0.6355349897210154, validation accuracy 0.3836750788643533\n",
      "Epoch 2: train loss 0.6664085024688093, train accuracy 0.37582966419136493, validation loss 0.6575666993198335, validation accuracy 0.38377365930599366\n",
      "Epoch 3: train loss 0.6476023156907544, train accuracy 0.3756982322402576, validation loss 0.6590814891297735, validation accuracy 0.38377365930599366\n",
      "Epoch 4: train loss 0.6388655644549861, train accuracy 0.3760268121180259, validation loss 0.6291686397997739, validation accuracy 0.38377365930599366\n",
      "Epoch 5: train loss 0.6293452568026624, train accuracy 0.3756982322402576, validation loss 0.6275296038257587, validation accuracy 0.3832807570977918\n",
      "Epoch 6: train loss 0.6161227675299611, train accuracy 0.37576394821581127, validation loss 0.6114663077453709, validation accuracy 0.38347791798107256\n",
      "Epoch 7: train loss 0.611068847920975, train accuracy 0.37635539199579415, validation loss 0.6133388292150167, validation accuracy 0.3839708201892745\n",
      "Epoch 8: train loss 0.5980504190059265, train accuracy 0.37517250443582834, validation loss 0.5872956630935429, validation accuracy 0.38347791798107256\n",
      "Epoch 9: train loss 0.5849422884260048, train accuracy 0.37655253992245513, validation loss 0.5830259466020843, validation accuracy 0.38337933753943215\n",
      "Epoch 10: train loss 0.5738771710217512, train accuracy 0.37582966419136493, validation loss 0.5676574447553616, validation accuracy 0.38387223974763407\n",
      "Epoch 11: train loss 0.5677499554901013, train accuracy 0.37530393638693565, validation loss 0.5659265427935387, validation accuracy 0.3839708201892745\n",
      "Epoch 12: train loss 0.5549919362559208, train accuracy 0.375435368338043, validation loss 0.5750902330837792, validation accuracy 0.38377365930599366\n",
      "Finished Training\n",
      "Training complete in 78m 12s\n",
      "Best model accuracy:  3895.0\n"
     ]
    }
   ],
   "source": [
    "train_rezult_metrics = train_model(\n",
    "    num_of_epoch,\n",
    "    #hwi_conv_neural_net,\n",
    "    resnet18,\n",
    "    dataset_loaders,\n",
    "    dataset_sizes,\n",
    "    criterion,\n",
    "    optimizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses, validation_losses, train_accuracies, validation_accuracies = train_rezult_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(len(train_losses)), train_losses, label='train')\n",
    "plt.plot(np.arange(len(validation_losses)), validation_losses, label='validation')\n",
    "plt.legend()\n",
    "plt.title(\"loss by epoch\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(np.arange(len(train_accuracies)), train_accuracies, label='train')\n",
    "plt.plot(np.arange(len(validation_accuracies)), validation_accuracies, label='validation')\n",
    "plt.legend()\n",
    "plt.title(\"accuracy by epoch\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.5779390118865857,\n",
       "  0.6664085024688093,\n",
       "  0.6476023156907544,\n",
       "  0.6388655644549861,\n",
       "  0.6293452568026624,\n",
       "  0.6161227675299611,\n",
       "  0.611068847920975,\n",
       "  0.5980504190059265,\n",
       "  0.5849422884260048,\n",
       "  0.5738771710217512,\n",
       "  0.5677499554901013,\n",
       "  0.5549919362559208],\n",
       " [0.6355349897210154,\n",
       "  0.6575666993198335,\n",
       "  0.6590814891297735,\n",
       "  0.6291686397997739,\n",
       "  0.6275296038257587,\n",
       "  0.6114663077453709,\n",
       "  0.6133388292150167,\n",
       "  0.5872956630935429,\n",
       "  0.5830259466020843,\n",
       "  0.5676574447553616,\n",
       "  0.5659265427935387,\n",
       "  0.5750902330837792],\n",
       " [0.3756982322402576,\n",
       "  0.37582966419136493,\n",
       "  0.3756982322402576,\n",
       "  0.3760268121180259,\n",
       "  0.3756982322402576,\n",
       "  0.37576394821581127,\n",
       "  0.37635539199579415,\n",
       "  0.37517250443582834,\n",
       "  0.37655253992245513,\n",
       "  0.37582966419136493,\n",
       "  0.37530393638693565,\n",
       "  0.375435368338043],\n",
       " [0.3836750788643533,\n",
       "  0.38377365930599366,\n",
       "  0.38377365930599366,\n",
       "  0.38377365930599366,\n",
       "  0.3832807570977918,\n",
       "  0.38347791798107256,\n",
       "  0.3839708201892745,\n",
       "  0.38347791798107256,\n",
       "  0.38337933753943215,\n",
       "  0.38387223974763407,\n",
       "  0.3839708201892745,\n",
       "  0.38377365930599366])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_rezult_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
