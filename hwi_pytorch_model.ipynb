{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import importlib\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import skimage\n",
    "#from skimage import io as img_io\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "#from torchvision import transforms\n",
    "from torch.utils import data\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "import load_data\n",
    "import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'model' from '/home/uldo/work/kaggle/competitions/Humpback_Whale_Identification/code/model.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.style.use('Solarize_Light2')\n",
    "%matplotlib inline\n",
    "importlib.reload(load_data)\n",
    "importlib.reload(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToTensor(object):\n",
    "    \n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "    def __init__(self, image_size=128):\n",
    "        self.image_size = image_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, label = sample['image'], sample['label']\n",
    "\n",
    "        # swap color axis because\n",
    "        # numpy image: H x W x C\n",
    "        # torch image: C X H X W\n",
    "        \n",
    "        \"\"\" The original code didn't expect gray scale images \"\"\"\n",
    "        \n",
    "        gray_scale_image = torch.zeros(\n",
    "            [self.image_size, self.image_size]\n",
    "        ).shape == image.shape\n",
    "        if gray_scale_image:\n",
    "            image = np.stack((image,) * 3, axis=-1)\n",
    "        #image = image.transpose((2, 0, 1))\n",
    "        print(\"image.shape: \", image.shape)\n",
    "        print(\"label: \", label)\n",
    "        return {'image': torch.from_numpy(image), 'label': torch.tensor(label, dtype=torch.uint8)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_loaders(dataset, valid_train_ratio=0.6):\n",
    "    dataset_size = len(dataset)\n",
    "    print(\"dataset_size: \", dataset_size)\n",
    "\n",
    "    validation_subset_size = int(dataset_size * (1 - valid_train_ratio))\n",
    "    print(\"validation_subset_size: \", validation_subset_size)\n",
    "\n",
    "    indices = list(range(dataset_size))\n",
    "    validation_indices = np.random.choice(indices, size=validation_subset_size, replace=False)\n",
    "    train_indices = list(set(indices) - set(validation_indices))\n",
    "\n",
    "    train_sampler = SubsetRandomSampler(train_indices)\n",
    "    validation_sampler = SubsetRandomSampler(validation_indices)\n",
    "    \n",
    "    dataset_sizes = {\n",
    "            'train': len(train_indices),\n",
    "            'validation': len(validation_indices)\n",
    "        }\n",
    "\n",
    "    train_loader = data.DataLoader(dataset, batch_size=BATCH_SIZE, num_workers=1, sampler=train_sampler)\n",
    "    validation_loader = data.DataLoader(dataset, batch_size=BATCH_SIZE, num_workers=1, sampler=validation_sampler)\n",
    "\n",
    "    loaders = {\n",
    "            'train': train_loader,\n",
    "            'validation': validation_loader\n",
    "        }\n",
    "\n",
    "    return loaders, dataset_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = load_data.load_text_data('../input/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_data.HumpbackWhalesDataset(\n",
    "    train_df,\n",
    "    #transform=load_data.transforms.ToTensor()\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_size:  25361\n",
      "validation_subset_size:  10144\n"
     ]
    }
   ],
   "source": [
    "dataset_loaders, dataset_sizes = prepare_loaders(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = dataset_loaders['train']\n",
    "validation_loader = dataset_loaders['validation']\n",
    "train_dataset_size = dataset_sizes['train']\n",
    "validation_dataset_size = dataset_sizes['validation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15217\n",
      "10144\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset_size)\n",
    "print(validation_dataset_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7f2fa8efe320>\n"
     ]
    }
   ],
   "source": [
    "print(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image.shape:  (700, 1050, 3)\n",
      "label:  217\n",
      "image.shape:  (620, 930, 3)\n",
      "label:  86\n",
      "image.shape:  (414, 1050, 3)\n",
      "label:  448\n",
      "image.shape:  (536, 1050, 3)\n",
      "label:  4562\n",
      "image.shape:  (525, 1050, 3)\n",
      "label:  3\n",
      "image.shape:  (600, 1050)\n",
      "label:  3\n",
      "image.shape:  (251, 740, 3)\n",
      "label:  941\n",
      "image.shape:  (700, 1050, 3)\n",
      "label:  1255\n",
      "image.shape:  (640, 1050, 3)\n",
      "label:  37\n",
      "image.shape:  (422, 1050, 3)\n",
      "label:  2571\n",
      "image.shape:  (250, 1050, 3)\n",
      "label:  92\n",
      "image.shape:  (450, 1050, 3)\n",
      "label:  384\n",
      "image.shape:  (450, 1050, 3)\n",
      "label:  447\n",
      "image.shape:  (175, 306, 3)\n",
      "label:  3227\n",
      "image.shape:  (525, 1050, 3)\n",
      "label:  3\n",
      "image.shape:  (342, 599, 3)\n",
      "label:  768\n",
      "image.shape:  (450, 1050, 3)\n",
      "label:  3\n",
      "image.shape:  (344, 802, 3)\n",
      "label:  3512\n",
      "image.shape:  (481, 1050, 3)\n",
      "label:  3\n",
      "image.shape:  (700, 1050, 3)\n",
      "label:  210\n",
      "image.shape:  (457, 811, 3)\n",
      "label:  1827\n",
      "image.shape:  (250, 1050, 3)\n",
      "label:  3\n",
      "image.shape:  (600, 1050, 3)\n",
      "label:  737\n",
      "image.shape:  (485, 848, 3)\n",
      "label:  2694\n",
      "image.shape:  (377, 1050, 3)\n",
      "label:  2764\n",
      "image.shape:  (146, 341, 3)\n",
      "label:  3745\n",
      "image.shape:  (270, 1050, 3)\n",
      "label:  4729\n",
      "image.shape:  (419, 1050, 3)\n",
      "label:  4828\n",
      "image.shape:  (401, 601, 3)\n",
      "label:  297\n",
      "image.shape:  (230, 640, 3)\n",
      "label:  3\n",
      "image.shape:  (445, 1050, 3)\n",
      "label:  3\n",
      "image.shape:  (450, 1050, 3)\n",
      "label:  3\n",
      "image.shape:  (630, 1050, 3)\n",
      "label:  297\n",
      "image.shape:  (667, 1000, 3)\n",
      "label:  612\n",
      "image.shape:  (585, 700)\n",
      "label:  3\n",
      "image.shape:  (591, 1050, 3)\n",
      "label:  250\n",
      "image.shape:  (600, 1050, 3)\n",
      "label:  776\n",
      "image.shape:  (500, 700)\n",
      "label:  3\n",
      "image.shape:  (450, 700)\n",
      "label:  3\n",
      "image.shape:  (396, 1050, 3)\n",
      "label:  3479\n",
      "image.shape:  (700, 1050, 3)\n",
      "label:  4067\n",
      "image.shape:  (450, 700)\n",
      "label:  3\n",
      "image.shape:  (493, 1050, 3)\n",
      "label:  3\n",
      "image.shape:  (381, 1050, 3)\n",
      "label:  195\n",
      "image.shape:  (429, 1050, 3)\n",
      "label:  27\n",
      "image.shape:  (750, 1050, 3)\n",
      "label:  58\n",
      "image.shape:  (430, 1050, 3)\n",
      "label:  20\n",
      "image.shape:  (836, 1050, 3)\n",
      "label:  3574\n",
      "image.shape:  (429, 1050, 3)\n",
      "label:  3\n",
      "image.shape:  (699, 1050, 3)\n",
      "label:  3413\n",
      "image.shape:  (500, 700)\n",
      "label:  3\n",
      "image.shape:  (426, 1050, 3)\n",
      "label:  3\n",
      "image.shape:  (700, 1050, 3)\n",
      "label:  778\n",
      "image.shape:  (753, 1050, 3)\n",
      "label:  3\n",
      "image.shape:  (460, 1050, 3)\n",
      "label:  3\n",
      "image.shape:  (630, 1050, 3)\n",
      "label:  976\n",
      "image.shape:  (600, 1050, 3)\n",
      "label:  130\n",
      "image.shape:  (406, 1050, 3)\n",
      "label:  22\n",
      "image.shape:  (525, 1050, 3)\n",
      "label:  4784\n",
      "image.shape:  (450, 1050, 3)\n",
      "label:  704\n",
      "image.shape:  (482, 1050, 3)\n",
      "label:  91\n",
      "image.shape:  (232, 852, 3)\n",
      "label:  1714\n",
      "image.shape:  (454, 1050, 3)\n",
      "label:  254\n",
      "image.shape:  (600, 1050, 3)\n",
      "label:  3179\n",
      "image.shape:  (405, 640, 3)\n",
      "label:  82\n",
      "image.shape:  (700, 1050, 3)\n",
      "label:  0\n",
      "image.shape:  (700, 1050, 3)\n",
      "label:  130\n",
      "image.shape:  (700, 1050, 3)\n",
      "label:  3682\n",
      "image.shape:  (390, 699, 3)\n",
      "label:  2790\n",
      "image.shape:  (575, 1006, 3)\n",
      "label:  92\n",
      "image.shape:  (808, 1050, 3)\n",
      "label:  3\n",
      "image.shape:  (713, 1000)\n",
      "label:  3\n",
      "image.shape:  (700, 1050, 3)\n",
      "label:  3\n",
      "image.shape:  (528, 792, 3)\n",
      "label:  570\n",
      "image.shape:  (436, 1050, 3)\n",
      "label:  929\n",
      "image.shape:  (345, 604, 3)\n",
      "label:  3\n",
      "image.shape:  (756, 1050, 3)\n",
      "label:  2750\n",
      "image.shape:  (600, 1050, 3)\n",
      "label:  618\n",
      "image.shape:  (479, 720, 3)\n",
      "label:  955\n",
      "image.shape:  (589, 886, 3)\n",
      "label:  3\n",
      "image.shape:  (775, 1050, 3)\n",
      "label:  3\n",
      "image.shape:  (527, 1050, 3)\n",
      "label:  3\n",
      "image.shape:  (450, 1050, 3)\n",
      "label:  3364\n",
      "image.shape:  (694, 1050, 3)\n",
      "label:  3\n",
      "image.shape:  (272, 1050, 3)\n",
      "label:  2324\n",
      "image.shape:  (379, 1050, 3)\n",
      "label:  2177\n",
      "image.shape:  (450, 1050, 3)\n",
      "label:  4723\n",
      "image.shape:  (450, 1050, 3)\n",
      "label:  3\n",
      "image.shape:  (525, 1050, 3)\n",
      "label:  3\n",
      "image.shape:  (700, 1050, 3)\n",
      "label:  3228\n",
      "image.shape:  (600, 1050, 3)\n",
      "label:  396\n",
      "image.shape:  (700, 1050, 3)\n",
      "label:  1697\n",
      "image.shape:  (700, 1050, 3)\n",
      "label:  4840\n",
      "image.shape:  (587, 1019)\n",
      "label:  3\n",
      "image.shape:  (450, 1050, 3)\n",
      "label:  625\n",
      "image.shape:  (500, 699)\n",
      "label:  3\n",
      "image.shape:  (288, 1050, 3)\n",
      "label:  941\n",
      "image.shape:  (744, 1086)\n",
      "label:  3\n",
      "image.shape:  (174, 1050, 3)\n",
      "label:  879\n",
      "image.shape:  (600, 1050)\n",
      "label:  3\n",
      "image.shape:  (700, 1050, 3)\n",
      "label:  707\n",
      "image.shape:  (450, 1050, 3)\n",
      "label:  3\n",
      "image.shape:  (197, 1050, 3)\n",
      "label:  225\n",
      "image.shape:  (401, 1050, 3)\n",
      "label:  2112\n",
      "image.shape:  (525, 1050, 3)\n",
      "label:  3\n",
      "image.shape:  (471, 824)\n",
      "label:  3833\n",
      "image.shape:  (754, 1050, 3)\n",
      "label:  3\n",
      "image.shape:  (600, 1050, 3)\n",
      "label:  844\n",
      "image.shape:  (500, 700)\n",
      "label:  3\n",
      "image.shape:  (700, 1050, 3)\n",
      "label:  1421\n",
      "image.shape:  (620, 752, 3)\n",
      "label:  3\n",
      "image.shape:  (444, 1050, 3)\n",
      "label:  2924\n",
      "image.shape:  (696, 1050, 3)\n",
      "label:  2924\n",
      "image.shape:  (450, 1050, 3)\n",
      "label:  1420\n",
      "image.shape:  (816, 1050, 3)\n",
      "label:  1967\n",
      "image.shape:  (296, 1050, 3)\n",
      "label:  172\n",
      "image.shape:  (332, 1050, 3)\n",
      "label:  886\n",
      "image.shape:  (183, 360, 3)\n",
      "label:  3\n",
      "image.shape:  (450, 1050, 3)\n",
      "label:  1615\n",
      "image.shape:  (450, 1050, 3)\n",
      "label:  1314\n"
     ]
    }
   ],
   "source": [
    "train_iter = iter(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.utils.data.dataloader._DataLoaderIter'>\n"
     ]
    }
   ],
   "source": [
    "print(type(train_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Traceback (most recent call last):\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 184, in default_collate\n    return {key: default_collate([d[key] for d in batch]) for key in batch[0]}\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 184, in <dictcomp>\n    return {key: default_collate([d[key] for d in batch]) for key in batch[0]}\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 164, in default_collate\n    return torch.stack(batch, 0, out=out)\nRuntimeError: invalid argument 0: Sizes of tensors must match except in dimension 0. Got 700 and 620 in dimension 1 at /opt/conda/conda-bld/pytorch_1533672544752/work/aten/src/TH/generic/THTensorMath.cpp:3616\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-4513cd221061>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/DS-New/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    334\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreorder_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_next_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[0mnext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__next__\u001b[0m  \u001b[0;31m# Python 2 compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/DS-New/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_next_batch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_put_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Traceback (most recent call last):\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 184, in default_collate\n    return {key: default_collate([d[key] for d in batch]) for key in batch[0]}\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 184, in <dictcomp>\n    return {key: default_collate([d[key] for d in batch]) for key in batch[0]}\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 164, in default_collate\n    return torch.stack(batch, 0, out=out)\nRuntimeError: invalid argument 0: Sizes of tensors must match except in dimension 0. Got 700 and 620 in dimension 1 at /opt/conda/conda-bld/pytorch_1533672544752/work/aten/src/TH/generic/THTensorMath.cpp:3616\n"
     ]
    }
   ],
   "source": [
    "images, labels = train_iter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
