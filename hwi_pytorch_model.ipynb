{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import importlib\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import skimage\n",
    "from skimage import transform as skimg_transform\n",
    "#from skimage import io as img_io\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, utils\n",
    "from torch.utils import data\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "import load_data\n",
    "import model\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'model' from '/home/uldo/work/kaggle/competitions/Humpback_Whale_Identification/code/model.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.style.use('Solarize_Light2')\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "importlib.reload(load_data)\n",
    "importlib.reload(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BATCH_SIZE = 100\n",
    "BATCH_SIZE = 32\n",
    "W = 128\n",
    "H = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nclass HWI_ConvNeuralNet(nn.Module):\\n    \\n    def __init__(self):\\n        super(HWI_ConvNeuralNet, self).__init__()\\n        self.conv1 = nn.Sequential(\\n            nn.Conv2d(3, 6, 5, 1, 2),\\n            nn.ReLU(),\\n            nn.MaxPool2d(kernel_size=2)\\n        )\\n        self.conv2 = nn.Sequential(\\n            nn.Conv2d(6, 12, 5, 1, 2),\\n            nn.ReLU(),\\n            nn.MaxPool2d(kernel_size=2)\\n        )\\n        self.drop_out = nn.Dropout()\\n        self.out1 = nn.Linear(int(12 * W/4 * H/4), 900)\\n        self.out2 = nn.Linear(900, 1)\\n        \\n    def forward(self, x):\\n        x = self.conv1(x)\\n        x = self.conv2(x)\\n        x = x.view(x.size(0), -1)\\n        output = self.drop_out(x)\\n        output = self.out1(x)\\n        output = self.out2(output)\\n        #return output, x\\n        return output[:, 0]\\n        #return F.log_softmax(output, dim=1)\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "class HWI_ConvNeuralNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(HWI_ConvNeuralNet, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 6, 5, 1, 2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(6, 12, 5, 1, 2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.drop_out = nn.Dropout()\n",
    "        self.out1 = nn.Linear(int(12 * W/4 * H/4), 900)\n",
    "        self.out2 = nn.Linear(900, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        output = self.drop_out(x)\n",
    "        output = self.out1(x)\n",
    "        output = self.out2(output)\n",
    "        #return output, x\n",
    "        return output[:, 0]\n",
    "        #return F.log_softmax(output, dim=1)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HWI_ConvNeuralNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(HWI_ConvNeuralNet, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 32, 7, padding=1)\n",
    "        self.conv2_bn = nn.BatchNorm2d(32)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)        \n",
    "        self.pool2 = nn.AvgPool2d(3, 3)\n",
    "        \n",
    "        self.fc1 = nn.Linear(64 * 4 * 4 * 16, 1024)\n",
    "        #self.fc1 = nn.Linear(64, 1024)\n",
    "        #self.fc2 = nn.Linear(1024, 5004)\n",
    "        self.fc2 = nn.Linear(1024, 1)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(\"forward, input x.size(): \", x.size())\n",
    "        x = self.pool(F.relu(self.conv2_bn(self.conv1(x))))\n",
    "        print(\"forward, x.size() after self.pool(F.relu(self.conv2_bn(self.conv1(x)))): \", x.size())\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        print(\"forward, x.size() after self.pool2(F.relu(self.conv2(x))): \", x.size())\n",
    "        x = x.view(-1, 64 * 4 * 4 * 16)\n",
    "        print(\"forward, x.size() after x.view(-1, 64 * 4 * 4 * 16): \", x.size())\n",
    "        x = F.relu(self.fc1(x))\n",
    "        print(\"forward, x.size() after F.relu(self.fc1(x)): \", x.size())\n",
    "        x = self.dropout(x)\n",
    "        print(\"forward, x.size() after self.dropout(x): \", x.size())\n",
    "        x = self.fc2(x)\n",
    "        print(\"forward, x.size() after self.fc2(x): \", x.size())\n",
    "        #x = self.fc3(x)\n",
    "        x = self.sigmoid(x)\n",
    "        print(\"forward, x.size() after self.sigmoid(x): \", x.size())\n",
    "        return x       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rescale(object):\n",
    "    \"\"\"Rescale the image in a sample to a given size.\n",
    "\n",
    "    Args:\n",
    "        output_size (tuple or int): Desired output size. If tuple, output is\n",
    "            matched to output_size. If int, smaller of image edges is matched\n",
    "            to output_size keeping aspect ratio the same.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, label = sample['image'], sample['label']\n",
    "\n",
    "        orig_height, orig_width = image.shape[:2]\n",
    "        if isinstance(self.output_size, int):\n",
    "            if orig_height > orig_width:\n",
    "                new_height, new_width = self.output_size * orig_height / orig_width, self.output_size\n",
    "            else:\n",
    "                new_height, new_width = self.output_size, self.output_size * orig_width / orig_height\n",
    "        else:\n",
    "            new_height, new_width = self.output_size\n",
    "\n",
    "        new_height, new_width = int(new_height), int(new_width)\n",
    "\n",
    "        img = skimg_transform.resize(image, (new_height, new_width))\n",
    "\n",
    "        return {'image': img, 'label': label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnifyRescale(object):\n",
    "    \n",
    "    def __init__(self, output_size=128):\n",
    "        assert isinstance(output_size, int)\n",
    "        self.output_size = output_size\n",
    "        \n",
    "    def __call__(self, sample):\n",
    "        image, label = sample['image'], sample['label']\n",
    "\n",
    "        img = skimg_transform.resize(image, (self.output_size, self.output_size))\n",
    "\n",
    "        return {'image': img, 'label': label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomCrop(object):\n",
    "    \"\"\"Crop randomly the image in a sample.\n",
    "\n",
    "    Args:\n",
    "        output_size (tuple or int): Desired output size. If int, square crop\n",
    "            is made.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        if isinstance(output_size, int):\n",
    "            self.output_size = (output_size, output_size)\n",
    "        else:\n",
    "            assert len(output_size) == 2\n",
    "            self.output_size = output_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, label = sample['image'], sample['label']\n",
    "\n",
    "        orig_height, orig_width = image.shape[:2]\n",
    "        new_height, new_width = self.output_size\n",
    "\n",
    "        top = np.random.randint(0, orig_height - new_height)\n",
    "        left = np.random.randint(0, orig_width - new_width)\n",
    "\n",
    "        image = image[top: top + new_height, left: left + new_width]\n",
    "\n",
    "        return {'image': image, 'label': label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToTensor(object):\n",
    "    \n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "    def __init__(self, image_size=128):\n",
    "        self.image_size = image_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, label = sample['image'], sample['label']\n",
    "\n",
    "        # swap color axis because\n",
    "        # numpy image: H x W x C\n",
    "        # torch image: C X H X W\n",
    "        \n",
    "        \"\"\" The original code didn't expect gray scale images \"\"\"\n",
    "        \n",
    "        gray_scale_image = torch.zeros(\n",
    "            [self.image_size, self.image_size]\n",
    "        ).shape == image.shape\n",
    "        if gray_scale_image:\n",
    "            image = np.stack((image,) * 3, axis=-1)\n",
    "        \n",
    "        image = image.transpose((2, 0, 1))\n",
    "        return {'image': torch.from_numpy(image), 'label': torch.tensor(label, dtype=torch.uint8)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_whale_batch(sample_batched):\n",
    "    \"\"\"Show whales for a batch of samples.\"\"\"\n",
    "    images_batch = sample_batched['image']\n",
    "    labels_batch = sample_batched['label']\n",
    "    batch_size = len(images_batch)\n",
    "    im_size = images_batch.size(2)\n",
    "\n",
    "    grid = utils.make_grid(images_batch)\n",
    "    plt.imshow(grid.numpy().transpose((1, 2, 0)))\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        plt.title('Batch from dataloader')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(submodule):\n",
    "    if type(submodule) == nn.Linear:\n",
    "        nn.init.xavier_uniform_(submodule.weight)\n",
    "        submodule.bias.data.fill_(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_loaders(dataset, valid_train_ratio=0.6):\n",
    "    dataset_size = len(dataset)\n",
    "    print(\"dataset_size: \", dataset_size)\n",
    "\n",
    "    validation_subset_size = int(dataset_size * (1 - valid_train_ratio))\n",
    "    print(\"validation_subset_size: \", validation_subset_size)\n",
    "\n",
    "    indices = list(range(dataset_size))\n",
    "    validation_indices = np.random.choice(indices, size=validation_subset_size, replace=False)\n",
    "    train_indices = list(set(indices) - set(validation_indices))\n",
    "\n",
    "    train_sampler = SubsetRandomSampler(train_indices)\n",
    "    validation_sampler = SubsetRandomSampler(validation_indices)\n",
    "    \n",
    "    dataset_sizes = {\n",
    "            'train': len(train_indices),\n",
    "            'validation': len(validation_indices)\n",
    "        }\n",
    "\n",
    "    #train_loader = data.DataLoader(dataset, batch_size=BATCH_SIZE, num_workers=1, sampler=train_sampler, pin_memory=True)\n",
    "    train_loader = data.DataLoader(dataset, batch_size=BATCH_SIZE, num_workers=1, sampler=train_sampler)\n",
    "    #validation_loader = data.DataLoader(dataset, batch_size=BATCH_SIZE, num_workers=1, sampler=validation_sampler, pin_memory=True)\n",
    "    validation_loader = data.DataLoader(dataset, batch_size=BATCH_SIZE, num_workers=1, sampler=validation_sampler)\n",
    "    loaders = {\n",
    "            'train': train_loader,\n",
    "            'validation': validation_loader\n",
    "        }\n",
    "\n",
    "    return loaders, dataset_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unfold_batch(batch):\n",
    "    return batch['image'], batch['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_epoch_train(model, data_loader, criterion, optimizer):\n",
    "    \n",
    "    accuracy = 0.0\n",
    "    total_loss = 0.0\n",
    "    correct_predicted_total = 0.0\n",
    "    \n",
    "    for i, data_batch in enumerate(data_loader, 0):\n",
    "        \n",
    "        inputs, labels = unfold_batch(data_batch)\n",
    "        #print(\"inputs: \", inputs)\n",
    "        #print(\"labels: \", labels)\n",
    "        inputs = inputs.to(device, dtype=torch.float)\n",
    "        labels = labels.to(device, dtype=torch.float)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = hwi_conv_neural_net(inputs)\n",
    "\n",
    "        #print(\"outputs.size():\\n\", outputs.size())\n",
    "        #print(\"labels.size():\\n\", labels.size())\n",
    "        #print(\"outputs:\\n\", outputs)\n",
    "        #print(\"outputs[:, 0]:\\n\", outputs[:, 0])\n",
    "        #print(\"labels:\\n\", labels)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "        predicted = outputs > 0\n",
    "        #print(\"type(predicted): \", type(predicted))\n",
    "        #print(\"predicted:\\n\", predicted)\n",
    "\n",
    "        #total += labels.size(0)\n",
    "        labels = labels.data.byte()\n",
    "        #print(\"predicted == labels:\\n\", predicted == labels)\n",
    "        #sum_of_correct_predicted = torch.sum((predicted == labels).all(1))\n",
    "        sum_of_correct_predicted = torch.sum((predicted == labels))\n",
    "        item = sum_of_correct_predicted.item()\n",
    "        correct_predicted_total += item\n",
    "        \n",
    "    accuracy = correct_predicted_total\n",
    "    \n",
    "    #epoch_train_loss = total_loss / train_dataset_size\n",
    "    #epoch_train_accuracy = correct_predicted_total / train_dataset_size\n",
    "    return (total_loss, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, validation_loader, criterion):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        correct_predicted_total = 0.0\n",
    "        total_loss = 0.0\n",
    "        #total = 0.0\n",
    "        \n",
    "        for data_batch in validation_loader:\n",
    "            inputs, labels = unfold_batch(data_batch)\n",
    "\n",
    "            inputs = inputs.to(device, dtype=torch.float)\n",
    "            #labels_as_float = labels.to(device, dtype=torch.float)\n",
    "            #labels = labels.to(device, dtype=torch.uint8)\n",
    "            labels = labels.to(device, dtype=torch.float)\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            #loss = criterion(outputs, labels_as_float)\n",
    "            total_loss += loss.item() * inputs.size(0)\n",
    "            \n",
    "            predicted = outputs > 0\n",
    "\n",
    "            #total += labels.size(0)\n",
    "            labels = labels.data.byte()\n",
    "            #sum_of_correct_predicted = torch.sum((predicted == labels).all(1))\n",
    "            sum_of_correct_predicted = torch.sum((predicted == labels))\n",
    "            item = sum_of_correct_predicted.item()\n",
    "\n",
    "            correct_predicted_total += item\n",
    "\n",
    "        #accuracy = correct_predicted_total / total\n",
    "        accuracy = correct_predicted_total\n",
    "        \n",
    "\n",
    "    return (total_loss, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_epoch_validate(model, data_loader, criterion):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        correct_predicted_total = 0.0\n",
    "        total_loss = 0.0\n",
    "        \n",
    "        for data_batch in data_loader:\n",
    "            inputs, labels = unfold_batch(data_batch)\n",
    "\n",
    "            inputs = inputs.to(device, dtype=torch.float)\n",
    "            labels = labels.to(device, dtype=torch.float)\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item() * inputs.size(0)\n",
    "            \n",
    "            predicted = outputs > 0\n",
    "            \n",
    "            labels = labels.data.byte()\n",
    "            sum_of_correct_predicted = torch.sum((predicted == labels))\n",
    "            item = sum_of_correct_predicted.item()\n",
    "\n",
    "            correct_predicted_total += item\n",
    "\n",
    "        accuracy = correct_predicted_total        \n",
    "\n",
    "    return (total_loss, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_epoch_model_process(model, loader, criterion, optimizer=None):\n",
    "    accuracy = 0.0\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for data_batch in loader:\n",
    "        inputs, labels = unfold_batch(data_batch)\n",
    "        inputs = inputs.to(device, dtype=torch.float)\n",
    "        labels = labels.to(device, dtype=torch.float)\n",
    "        outputs = model(inputs)[:, 0]\n",
    "            \n",
    "        loss = criterion(outputs, labels)\n",
    "        if optimizer:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        total_loss += loss.item() * inputs.size(0)\n",
    "            \n",
    "        predicted = outputs > 0\n",
    "\n",
    "        labels = labels.data.byte()\n",
    "        #torch_sum_of_correct_predicted = torch.sum((predicted == labels).all(1))\n",
    "        torch_sum_of_correct_predicted = torch.sum((predicted == labels))\n",
    "        correct_predicted = torch_sum_of_correct_predicted.item()\n",
    "\n",
    "        accuracy += correct_predicted        \n",
    "\n",
    "    return (total_loss, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(num_of_epoch, model, dataset_loaders, dataset_sizes, criterion, optimizer):\n",
    "    torch.cuda.empty_cache()\n",
    "    since = time.time()\n",
    "    \n",
    "    train_loader = dataset_loaders['train']\n",
    "    validation_loader = dataset_loaders['validation']\n",
    "    train_dataset_size = dataset_sizes['train']\n",
    "    validation_dataset_size = dataset_sizes['validation']\n",
    "    \n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    validation_losses = []\n",
    "    validation_accuracies = []\n",
    "    \n",
    "    for epoch in range(num_of_epoch):\n",
    "        \n",
    "        train_loss, train_accuracy = one_epoch_train(model, train_loader, criterion, optimizer)\n",
    "        train_losses.append(train_loss / train_dataset_size)\n",
    "        train_accuracies.append(train_accuracy / train_dataset_size)\n",
    "        \n",
    "        validation_loss, validation_accuracy = one_epoch_validate(model, validation_loader, criterion)\n",
    "        validation_losses.append(validation_loss / validation_dataset_size)\n",
    "        validation_accuracies.append(validation_accuracy / validation_dataset_size)\n",
    "        \n",
    "        print(\"Epoch {}: train loss {}, train accuracy\"\n",
    "          \" {}, validation loss {}, validation accuracy {}\".format(\n",
    "              epoch + 1,\n",
    "              train_loss / train_dataset_size,\n",
    "              train_accuracy / train_dataset_size,\n",
    "              validation_loss / validation_dataset_size,\n",
    "              validation_accuracy / validation_dataset_size\n",
    "            )\n",
    "        )\n",
    "    print(\"Finished Training\")\n",
    "    time_elapsed = time.time() - since\n",
    "    print(\n",
    "            'Training complete in {:.0f}m {:.0f}s'.format(\n",
    "            time_elapsed // 60, time_elapsed % 60\n",
    "        )\n",
    "    )\n",
    "    return train_losses, validation_losses, train_accuracies, validation_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(model, batch):\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    #inputs = batch\n",
    "    #inputs = inputs.to(device, dtype=torch.float)\n",
    "    inputs = batch.to(device, dtype=torch.float)\n",
    "    outputs = model(inputs)\n",
    "    #return outputs[0].cpu()\n",
    "    return outputs.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, full=True, name='model'):\n",
    "    if not full:\n",
    "        torch.save(model.state_dict(), '{}_params.pkl'.format(name))\n",
    "    else:\n",
    "        torch.save(model, '{}.pkl'.format(name))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restore_model(name='model'):\n",
    "    return torch.load('{}.pkl'.format(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = load_data.load_text_data('../input/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_two_classes = train_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_two_classes.loc[train_df_two_classes['Id'] != 'new_whale', 'Id'] = 'not_new_whale'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000e88ab.jpg</td>\n",
       "      <td>not_new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0001f9222.jpg</td>\n",
       "      <td>not_new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00029d126.jpg</td>\n",
       "      <td>not_new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00050a15a.jpg</td>\n",
       "      <td>new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0005c1ef8.jpg</td>\n",
       "      <td>new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0006e997e.jpg</td>\n",
       "      <td>new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>000a6daec.jpg</td>\n",
       "      <td>not_new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>000f0f2bf.jpg</td>\n",
       "      <td>new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0016b897a.jpg</td>\n",
       "      <td>not_new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>001c1ac5f.jpg</td>\n",
       "      <td>not_new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>001cae55b.jpg</td>\n",
       "      <td>not_new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>001d7450c.jpg</td>\n",
       "      <td>new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>00200e115.jpg</td>\n",
       "      <td>new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>00245a598.jpg</td>\n",
       "      <td>new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>002b4615d.jpg</td>\n",
       "      <td>new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>002f99f01.jpg</td>\n",
       "      <td>new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>00355ff28.jpg</td>\n",
       "      <td>not_new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>00357e37a.jpg</td>\n",
       "      <td>not_new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>003795857.jpg</td>\n",
       "      <td>new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0041880bf.jpg</td>\n",
       "      <td>new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0043da555.jpg</td>\n",
       "      <td>new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>00442c882.jpg</td>\n",
       "      <td>not_new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>00464ff65.jpg</td>\n",
       "      <td>new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>004775679.jpg</td>\n",
       "      <td>not_new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>004ae9e26.jpg</td>\n",
       "      <td>new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>004c0f43b.jpg</td>\n",
       "      <td>new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>004e8ad5b.jpg</td>\n",
       "      <td>not_new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>004f87702.jpg</td>\n",
       "      <td>not_new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0050ef29d.jpg</td>\n",
       "      <td>not_new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>00514c876.jpg</td>\n",
       "      <td>not_new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0052ce2f5.jpg</td>\n",
       "      <td>not_new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>00537ec91.jpg</td>\n",
       "      <td>not_new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>00570db6b.jpg</td>\n",
       "      <td>not_new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>005ce3100.jpg</td>\n",
       "      <td>new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>00600ce17.jpg</td>\n",
       "      <td>new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>006017ddf.jpg</td>\n",
       "      <td>not_new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0060f764a.jpg</td>\n",
       "      <td>not_new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>006500b3d.jpg</td>\n",
       "      <td>not_new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>006506edf.jpg</td>\n",
       "      <td>new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0067b3a20.jpg</td>\n",
       "      <td>not_new_whale</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Image             Id\n",
       "0   0000e88ab.jpg  not_new_whale\n",
       "1   0001f9222.jpg  not_new_whale\n",
       "2   00029d126.jpg  not_new_whale\n",
       "3   00050a15a.jpg      new_whale\n",
       "4   0005c1ef8.jpg      new_whale\n",
       "5   0006e997e.jpg      new_whale\n",
       "6   000a6daec.jpg  not_new_whale\n",
       "7   000f0f2bf.jpg      new_whale\n",
       "8   0016b897a.jpg  not_new_whale\n",
       "9   001c1ac5f.jpg  not_new_whale\n",
       "10  001cae55b.jpg  not_new_whale\n",
       "11  001d7450c.jpg      new_whale\n",
       "12  00200e115.jpg      new_whale\n",
       "13  00245a598.jpg      new_whale\n",
       "14  002b4615d.jpg      new_whale\n",
       "15  002f99f01.jpg      new_whale\n",
       "16  00355ff28.jpg  not_new_whale\n",
       "17  00357e37a.jpg  not_new_whale\n",
       "18  003795857.jpg      new_whale\n",
       "19  0041880bf.jpg      new_whale\n",
       "20  0043da555.jpg      new_whale\n",
       "21  00442c882.jpg  not_new_whale\n",
       "22  00464ff65.jpg      new_whale\n",
       "23  004775679.jpg  not_new_whale\n",
       "24  004ae9e26.jpg      new_whale\n",
       "25  004c0f43b.jpg      new_whale\n",
       "26  004e8ad5b.jpg  not_new_whale\n",
       "27  004f87702.jpg  not_new_whale\n",
       "28  0050ef29d.jpg  not_new_whale\n",
       "29  00514c876.jpg  not_new_whale\n",
       "30  0052ce2f5.jpg  not_new_whale\n",
       "31  00537ec91.jpg  not_new_whale\n",
       "32  00570db6b.jpg  not_new_whale\n",
       "33  005ce3100.jpg      new_whale\n",
       "34  00600ce17.jpg      new_whale\n",
       "35  006017ddf.jpg  not_new_whale\n",
       "36  0060f764a.jpg  not_new_whale\n",
       "37  006500b3d.jpg  not_new_whale\n",
       "38  006506edf.jpg      new_whale\n",
       "39  0067b3a20.jpg  not_new_whale"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_two_classes.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimage_size = 128\\ndataset = load_data.HumpbackWhalesDataset(\\n    train_df_two_classes,\\n    #train_df,\\n    #transform=load_data.transforms.ToTensor()\\n    #transform=ToTensor()\\n    transform=transforms.Compose(\\n        [\\n            #Rescale(int(image_size*1.25)),\\n            Rescale(int(image_size)),\\n            #RandomCrop(image_size),\\n            UnifyRescale(int(image_size)),\\n            ToTensor()\\n        ]\\n    )\\n)\\n'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "image_size = 128\n",
    "dataset = load_data.HumpbackWhalesDataset(\n",
    "    train_df_two_classes,\n",
    "    #train_df,\n",
    "    #transform=load_data.transforms.ToTensor()\n",
    "    #transform=ToTensor()\n",
    "    transform=transforms.Compose(\n",
    "        [\n",
    "            #Rescale(int(image_size*1.25)),\n",
    "            Rescale(int(image_size)),\n",
    "            #RandomCrop(image_size),\n",
    "            UnifyRescale(int(image_size)),\n",
    "            ToTensor()\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 128\n",
    "#image_size = 100\n",
    "dataset = load_data.HumpbackWhalesDataset(\n",
    "    train_df_two_classes,\n",
    "    #train_df,\n",
    "    #transform=load_data.transforms.ToTensor()\n",
    "    #transform=ToTensor()\n",
    "    transform=transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize((image_size, image_size)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225]\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_size:  25361\n",
      "validation_subset_size:  10144\n"
     ]
    }
   ],
   "source": [
    "dataset_loaders, dataset_sizes = prepare_loaders(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = dataset_loaders['train']\n",
    "validation_loader = dataset_loaders['validation']\n",
    "train_dataset_size = dataset_sizes['train']\n",
    "validation_dataset_size = dataset_sizes['validation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15217\n",
      "10144\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset_size)\n",
    "print(validation_dataset_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7f9fa6b71d68>\n"
     ]
    }
   ],
   "source": [
    "print(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-1:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "train_iter = iter(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.utils.data.dataloader._DataLoaderIter'>\n"
     ]
    }
   ],
   "source": [
    "print(type(train_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image': tensor([[[[ 1.5468,  1.4612,  1.4612,  ...,  1.9064,  1.7865,  1.6495],\n",
      "          [ 1.5297,  1.5125,  1.5125,  ...,  1.9407,  1.8037,  1.6838],\n",
      "          [ 1.3927,  1.1700,  0.8447,  ...,  2.1290,  2.0777,  1.7865],\n",
      "          ...,\n",
      "          [ 1.3927,  1.4612,  1.3927,  ...,  2.1290,  2.2147,  2.2318],\n",
      "          [ 1.3584,  1.5297,  1.6838,  ...,  2.2318,  2.2489,  2.2489],\n",
      "          [ 1.8379,  1.9235,  2.0263,  ...,  2.2489,  2.2147,  2.1975]],\n",
      "\n",
      "         [[ 1.7108,  1.6232,  1.6232,  ...,  2.0784,  1.9559,  1.8158],\n",
      "          [ 1.6933,  1.6758,  1.6758,  ...,  2.1134,  1.9734,  1.8508],\n",
      "          [ 1.5532,  1.3256,  0.9930,  ...,  2.3060,  2.2535,  1.9559],\n",
      "          ...,\n",
      "          [ 1.5532,  1.6232,  1.5532,  ...,  2.3060,  2.3936,  2.4111],\n",
      "          [ 1.5182,  1.6933,  1.8508,  ...,  2.4111,  2.4286,  2.4286],\n",
      "          [ 2.0084,  2.0959,  2.2010,  ...,  2.4286,  2.3936,  2.3761]],\n",
      "\n",
      "         [[ 1.9254,  1.8383,  1.8383,  ...,  2.2914,  2.1694,  2.0300],\n",
      "          [ 1.9080,  1.8905,  1.8905,  ...,  2.3263,  2.1868,  2.0648],\n",
      "          [ 1.7685,  1.5420,  1.2108,  ...,  2.5180,  2.4657,  2.1694],\n",
      "          ...,\n",
      "          [ 1.7685,  1.8383,  1.7685,  ...,  2.5180,  2.6051,  2.6226],\n",
      "          [ 1.7337,  1.9080,  2.0648,  ...,  2.6226,  2.6400,  2.6400],\n",
      "          [ 2.2217,  2.3088,  2.4134,  ...,  2.6400,  2.6051,  2.5877]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6221,  0.6221,  0.6221,  ...,  0.4166,  0.4166,  0.4337],\n",
      "          [ 0.6049,  0.6049,  0.5878,  ...,  0.4337,  0.4166,  0.4166],\n",
      "          [ 0.5878,  0.5878,  0.5878,  ...,  0.4166,  0.4166,  0.4166],\n",
      "          ...,\n",
      "          [-1.1760, -0.6965, -0.4911,  ...,  0.1597,  0.2111,  0.1768],\n",
      "          [-0.8678, -0.6794, -0.7137,  ..., -0.0801, -0.0801, -0.0972],\n",
      "          [-0.9363, -1.0733, -0.9020,  ..., -0.3712, -0.3541, -0.2856]],\n",
      "\n",
      "         [[ 0.9930,  0.9755,  0.9930,  ...,  0.8529,  0.8529,  0.8354],\n",
      "          [ 0.9930,  0.9755,  0.9755,  ...,  0.8529,  0.8529,  0.8354],\n",
      "          [ 0.9755,  0.9755,  0.9755,  ...,  0.8354,  0.8354,  0.8354],\n",
      "          ...,\n",
      "          [-0.9853, -0.5476, -0.3375,  ...,  0.4328,  0.4678,  0.4503],\n",
      "          [-0.6527, -0.4951, -0.5301,  ...,  0.1702,  0.2052,  0.1877],\n",
      "          [-0.7577, -0.9153, -0.7577,  ..., -0.1099, -0.0399,  0.0301]],\n",
      "\n",
      "         [[ 1.3677,  1.4025,  1.3677,  ...,  1.3154,  1.3154,  1.3154],\n",
      "          [ 1.3851,  1.3851,  1.3851,  ...,  1.2980,  1.3154,  1.3154],\n",
      "          [ 1.3851,  1.3851,  1.4025,  ...,  1.2980,  1.3154,  1.3154],\n",
      "          ...,\n",
      "          [-0.6541, -0.2358, -0.0615,  ...,  0.7925,  0.8099,  0.7925],\n",
      "          [-0.3404, -0.1835, -0.2358,  ...,  0.5659,  0.5834,  0.5834],\n",
      "          [-0.4275, -0.6018, -0.4624,  ...,  0.3219,  0.4091,  0.4788]]],\n",
      "\n",
      "\n",
      "        [[[-0.9192, -0.9705, -1.0733,  ..., -0.8335, -0.8164, -0.8164],\n",
      "          [-0.6965, -0.7308, -0.9020,  ..., -0.6109, -0.5082, -0.7137],\n",
      "          [-1.0904, -0.7650, -0.5082,  ..., -0.6452, -0.4911, -0.6452],\n",
      "          ...,\n",
      "          [-1.2445, -1.2274, -1.0048,  ..., -0.0287,  0.3481,  0.5707],\n",
      "          [-0.9192, -1.0048, -0.8678,  ..., -0.2513, -0.0972,  0.0569],\n",
      "          [-1.0219, -0.9363, -0.6965,  ...,  0.2453,  0.1426,  0.2111]],\n",
      "\n",
      "         [[-0.1099, -0.2150, -0.2850,  ...,  0.0826,  0.1001,  0.1352],\n",
      "          [ 0.1527,  0.0301, -0.1450,  ...,  0.2052,  0.3452,  0.0476],\n",
      "          [-0.2500,  0.0826,  0.3102,  ...,  0.2052,  0.2927,  0.1527],\n",
      "          ...,\n",
      "          [-0.4776, -0.4951, -0.1975,  ...,  0.7304,  0.9755,  1.0455],\n",
      "          [-0.1099, -0.1450, -0.0749,  ...,  0.4153,  0.5728,  0.6604],\n",
      "          [-0.2325, -0.0924,  0.1176,  ...,  0.8179,  0.6429,  0.7304]],\n",
      "\n",
      "         [[ 0.7576,  0.6531,  0.5659,  ...,  1.0017,  0.9842,  1.0017],\n",
      "          [ 1.0017,  0.8971,  0.7228,  ...,  1.1411,  1.2282,  1.0017],\n",
      "          [ 0.6008,  0.9668,  1.1934,  ...,  1.1062,  1.1934,  1.0888],\n",
      "          ...,\n",
      "          [ 0.0605,  0.1128,  0.5659,  ...,  1.4548,  1.6291,  1.7163],\n",
      "          [ 0.6531,  0.5834,  0.7228,  ...,  1.1759,  1.2805,  1.3328],\n",
      "          [ 0.4962,  0.6705,  0.9319,  ...,  1.3677,  1.1934,  1.2631]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 1.6324,  1.6838,  1.6838,  ...,  1.2557,  1.3927,  1.4612],\n",
      "          [ 1.6838,  1.7009,  1.6495,  ...,  1.4098,  1.5125,  1.5810],\n",
      "          [ 1.6667,  1.6667,  1.6153,  ...,  1.4954,  1.5468,  1.5810],\n",
      "          ...,\n",
      "          [ 1.7694,  1.7009,  1.8379,  ...,  1.6153,  1.6153,  1.5468],\n",
      "          [ 1.3584,  1.4269,  1.6495,  ...,  1.9235,  1.6324,  1.6667],\n",
      "          [ 1.1700,  1.2557,  1.4098,  ...,  1.9407,  1.6838,  1.7694]],\n",
      "\n",
      "         [[ 1.7983,  1.8508,  1.8508,  ...,  1.4132,  1.5532,  1.6232],\n",
      "          [ 1.8508,  1.8683,  1.8158,  ...,  1.5707,  1.6758,  1.7458],\n",
      "          [ 1.8333,  1.8333,  1.7808,  ...,  1.6583,  1.7108,  1.7458],\n",
      "          ...,\n",
      "          [ 1.9384,  1.8683,  2.0084,  ...,  1.7808,  1.7808,  1.7108],\n",
      "          [ 1.5182,  1.5882,  1.8158,  ...,  2.0959,  1.7983,  1.8333],\n",
      "          [ 1.3256,  1.4132,  1.5707,  ...,  2.1134,  1.8508,  1.9384]],\n",
      "\n",
      "         [[ 2.0125,  2.0648,  2.0648,  ...,  1.6291,  1.7685,  1.8383],\n",
      "          [ 2.0648,  2.0823,  2.0300,  ...,  1.7860,  1.8905,  1.9603],\n",
      "          [ 2.0474,  2.0474,  1.9951,  ...,  1.8731,  1.9254,  1.9603],\n",
      "          ...,\n",
      "          [ 2.1520,  2.0823,  2.2217,  ...,  1.9951,  1.9951,  1.9254],\n",
      "          [ 1.7337,  1.8034,  2.0300,  ...,  2.3088,  2.0125,  2.0474],\n",
      "          [ 1.5420,  1.6291,  1.7860,  ...,  2.3263,  2.0648,  2.1520]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2453,  0.4337,  0.4679,  ..., -0.1657, -0.0801, -0.0972],\n",
      "          [ 0.1939,  0.3138,  0.3652,  ..., -0.4911, -0.3369, -0.0801],\n",
      "          [-0.7993, -0.8678, -0.8678,  ..., -0.8335, -0.8507, -0.6109],\n",
      "          ...,\n",
      "          [ 0.0398,  0.2796,  0.0227,  ..., -0.4397, -0.3541, -0.2856],\n",
      "          [-0.0116,  0.2111, -0.0287,  ..., -0.9363, -1.0048, -0.7993],\n",
      "          [-0.5424, -0.2342, -0.0801,  ..., -0.2171, -0.5424, -0.2342]],\n",
      "\n",
      "         [[ 0.7479,  0.9405,  0.9580,  ...,  0.3803,  0.4853,  0.4503],\n",
      "          [ 0.7129,  0.8529,  0.8704,  ...,  0.0476,  0.2227,  0.4503],\n",
      "          [-0.2675, -0.3025, -0.3550,  ..., -0.2325, -0.2325, -0.0399],\n",
      "          ...,\n",
      "          [ 0.5728,  0.7654,  0.5553,  ...,  0.1702,  0.2752,  0.3102],\n",
      "          [ 0.5553,  0.7654,  0.4678,  ..., -0.3901, -0.4251, -0.2150],\n",
      "          [ 0.1001,  0.3978,  0.4853,  ...,  0.2927, -0.0049,  0.2752]],\n",
      "\n",
      "         [[ 1.3851,  1.5420,  1.5420,  ...,  1.1237,  1.2108,  1.1759],\n",
      "          [ 1.3502,  1.4897,  1.5420,  ...,  0.8099,  0.9842,  1.2108],\n",
      "          [ 0.5136,  0.4614,  0.4091,  ...,  0.4962,  0.4962,  0.7228],\n",
      "          ...,\n",
      "          [ 1.1759,  1.3851,  1.1759,  ...,  0.8622,  0.9668,  1.0017],\n",
      "          [ 1.1934,  1.4025,  1.1237,  ...,  0.2696,  0.2522,  0.4962],\n",
      "          [ 0.7751,  1.0539,  1.1237,  ...,  0.9494,  0.6705,  0.9319]]],\n",
      "\n",
      "\n",
      "        [[[ 0.9817,  0.8618,  0.5536,  ..., -1.5870, -1.3644, -1.3815],\n",
      "          [ 0.8789,  0.7248,  0.2967,  ..., -1.6555, -1.4672, -1.5185],\n",
      "          [ 0.8961,  0.4851,  0.1597,  ..., -1.5357, -1.5185, -1.5357],\n",
      "          ...,\n",
      "          [-1.6042, -1.5870, -1.7925,  ..., -2.0323, -2.0837, -2.1179],\n",
      "          [-1.5699, -1.4158, -1.6727,  ..., -1.8268, -1.9124, -1.9467],\n",
      "          [-1.7240, -1.5699, -1.5870,  ..., -1.6384, -1.6213, -1.6898]],\n",
      "\n",
      "         [[ 1.2031,  1.1155,  0.8179,  ..., -1.3179, -1.1078, -1.1429],\n",
      "          [ 1.1506,  0.9755,  0.5728,  ..., -1.3354, -1.1604, -1.2654],\n",
      "          [ 1.2206,  0.7829,  0.4503,  ..., -1.1429, -1.1429, -1.1779],\n",
      "          ...,\n",
      "          [-0.9503, -0.9153, -1.1253,  ..., -1.3880, -1.4405, -1.5280],\n",
      "          [-0.8978, -0.7227, -0.9853,  ..., -1.1779, -1.2829, -1.3179],\n",
      "          [-1.0378, -0.8803, -0.8978,  ..., -1.0028, -1.0028, -1.0553]],\n",
      "\n",
      "         [[ 1.4025,  1.2631,  0.9668,  ..., -1.0201, -0.8284, -0.8633],\n",
      "          [ 1.3328,  1.1585,  0.7402,  ..., -0.9678, -0.8284, -0.9330],\n",
      "          [ 1.4200,  0.9842,  0.6705,  ..., -0.7064, -0.7064, -0.7587],\n",
      "          ...,\n",
      "          [-0.3230, -0.2532, -0.4450,  ..., -0.7587, -0.8110, -0.9156],\n",
      "          [-0.2707, -0.0615, -0.3230,  ..., -0.5495, -0.6541, -0.7238],\n",
      "          [-0.3927, -0.2184, -0.2184,  ..., -0.3578, -0.3753, -0.4624]]]]), 'label': tensor([0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
      "        0, 0, 1, 0, 1, 0, 1, 1])}\n"
     ]
    }
   ],
   "source": [
    "#images, labels = train_iter.next()\n",
    "sample = train_iter.next()\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfor i_batch, sample_batched in enumerate(train_loader):\\n    print(i_batch, sample_batched['image'].size(),\\n          sample_batched['label'])\\n    # observe 4th batch and stop.\\n    if i_batch == 0:\\n        plt.figure(figsize=(24, 24))\\n        show_whale_batch(sample_batched)\\n        plt.axis('off')\\n        #plt.ioff()\\n        plt.show()\\n        break\\n\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "for i_batch, sample_batched in enumerate(train_loader):\n",
    "    print(i_batch, sample_batched['image'].size(),\n",
    "          sample_batched['label'])\n",
    "    # observe 4th batch and stop.\n",
    "    if i_batch == 0:\n",
    "        plt.figure(figsize=(24, 24))\n",
    "        show_whale_batch(sample_batched)\n",
    "        plt.axis('off')\n",
    "        #plt.ioff()\n",
    "        plt.show()\n",
    "        break\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'not_new_whale': 0, 'new_whale': 1}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "hwi_conv_neural_net = HWI_ConvNeuralNet()\n",
    "#hwi_conv_neural_net.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HWI_ConvNeuralNet(\n",
       "  (conv1): Conv2d(3, 32, kernel_size=(7, 7), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2_bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool2): AvgPool2d(kernel_size=3, stride=3, padding=0)\n",
       "  (fc1): Linear(in_features=16384, out_features=1024, bias=True)\n",
       "  (fc2): Linear(in_features=1024, out_features=1, bias=True)\n",
       "  (dropout): Dropout(p=0.5)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hwi_conv_neural_net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#criterion = nn.BCEWithLogitsLoss(reduction='sum')\n",
    "#criterion = nn.BCEWithLogitsLoss()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(hwi_conv_neural_net.parameters(), lr=0.001, betas=(0.9, 0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_epoch = 12\n",
    "#train_losses = []\n",
    "#train_accuracies = []\n",
    "#validation_losses = []\n",
    "#validation_accuracies = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntorch.cuda.empty_cache()\\nsince = time.time()\\nfor epoch in range(num_of_epoch):\\n    epoch_train_accuracy = 0.0\\n    epoch_train_loss = 0.0\\n    correct_predicted_total = 0.0\\n    train_loss = 0.0\\n    #total_loss = 0.0\\n    #total = 0.0\\n    for i, data_batch in enumerate(train_loader, 0):\\n        \\n        inputs = data_batch[\\'image\\']\\n        labels = data_batch[\\'label\\']\\n        print(\"inputs: \", inputs)\\n        print(\"labels: \", labels)\\n        inputs = inputs.to(device, dtype=torch.float)\\n        labels = labels.to(device, dtype=torch.float)\\n        optimizer.zero_grad()\\n        \\n        outputs = hwi_conv_neural_net(inputs)\\n\\n        print(\"outputs.size():\\n\", outputs.size())\\n        print(\"labels.size():\\n\", labels.size())\\n        print(\"outputs:\\n\", outputs)\\n        #print(\"outputs[:, 0]:\\n\", outputs[:, 0])\\n        print(\"labels:\\n\", labels)\\n        loss = criterion(outputs, labels)\\n        loss.backward()\\n        optimizer.step()\\n        \\n        train_loss += loss.item() * inputs.size(0)\\n        \\n        predicted = outputs > 0\\n        print(\"type(predicted): \", type(predicted))\\n        print(\"predicted:\\n\", predicted)\\n\\n        #total += labels.size(0)\\n        labels = labels.data.byte()\\n        print(\"predicted == labels:\\n\", predicted == labels)\\n        #sum_of_correct_predicted = torch.sum((predicted == labels).all(1))\\n        sum_of_correct_predicted = torch.sum((predicted == labels))\\n        item = sum_of_correct_predicted.item()\\n        correct_predicted_total += item\\n        \\n    epoch_train_loss = train_loss / train_dataset_size\\n    epoch_train_accuracy = correct_predicted_total / train_dataset_size\\n    \\n    validation_loss, validation_accuracy = validate(hwi_conv_neural_net, validation_loader, criterion)\\n    \\n    epoch_validation_loss = validation_loss / validation_dataset_size\\n    epoch_validation_accuracy = validation_accuracy / validation_dataset_size\\n    \\n    print(\"Epoch {}: train loss {}, train accuracy\"\\n          \" {}, validation loss {}, validation accuracy {}\".format(\\n              epoch + 1,\\n              epoch_train_loss,\\n              epoch_train_accuracy,\\n              epoch_validation_loss,\\n              epoch_validation_accuracy\\n        )\\n    )\\n    train_losses.append(epoch_train_loss)\\n    train_accuracies.append(epoch_train_accuracy)\\n    validation_losses.append(epoch_validation_loss)\\n    validation_accuracies.append(epoch_validation_accuracy)\\n            \\nprint(\"Finished Training\")\\ntime_elapsed = time.time() - since\\nprint(\\n    \\'Training complete in {:.0f}m {:.0f}s\\'.format(\\n        time_elapsed // 60, time_elapsed % 60\\n    )\\n)\\n'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "torch.cuda.empty_cache()\n",
    "since = time.time()\n",
    "for epoch in range(num_of_epoch):\n",
    "    epoch_train_accuracy = 0.0\n",
    "    epoch_train_loss = 0.0\n",
    "    correct_predicted_total = 0.0\n",
    "    train_loss = 0.0\n",
    "    #total_loss = 0.0\n",
    "    #total = 0.0\n",
    "    for i, data_batch in enumerate(train_loader, 0):\n",
    "        \n",
    "        inputs = data_batch['image']\n",
    "        labels = data_batch['label']\n",
    "        print(\"inputs: \", inputs)\n",
    "        print(\"labels: \", labels)\n",
    "        inputs = inputs.to(device, dtype=torch.float)\n",
    "        labels = labels.to(device, dtype=torch.float)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = hwi_conv_neural_net(inputs)\n",
    "\n",
    "        print(\"outputs.size():\\n\", outputs.size())\n",
    "        print(\"labels.size():\\n\", labels.size())\n",
    "        print(\"outputs:\\n\", outputs)\n",
    "        #print(\"outputs[:, 0]:\\n\", outputs[:, 0])\n",
    "        print(\"labels:\\n\", labels)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "        predicted = outputs > 0\n",
    "        print(\"type(predicted): \", type(predicted))\n",
    "        print(\"predicted:\\n\", predicted)\n",
    "\n",
    "        #total += labels.size(0)\n",
    "        labels = labels.data.byte()\n",
    "        print(\"predicted == labels:\\n\", predicted == labels)\n",
    "        #sum_of_correct_predicted = torch.sum((predicted == labels).all(1))\n",
    "        sum_of_correct_predicted = torch.sum((predicted == labels))\n",
    "        item = sum_of_correct_predicted.item()\n",
    "        correct_predicted_total += item\n",
    "        \n",
    "    epoch_train_loss = train_loss / train_dataset_size\n",
    "    epoch_train_accuracy = correct_predicted_total / train_dataset_size\n",
    "    \n",
    "    validation_loss, validation_accuracy = validate(hwi_conv_neural_net, validation_loader, criterion)\n",
    "    \n",
    "    epoch_validation_loss = validation_loss / validation_dataset_size\n",
    "    epoch_validation_accuracy = validation_accuracy / validation_dataset_size\n",
    "    \n",
    "    print(\"Epoch {}: train loss {}, train accuracy\"\n",
    "          \" {}, validation loss {}, validation accuracy {}\".format(\n",
    "              epoch + 1,\n",
    "              epoch_train_loss,\n",
    "              epoch_train_accuracy,\n",
    "              epoch_validation_loss,\n",
    "              epoch_validation_accuracy\n",
    "        )\n",
    "    )\n",
    "    train_losses.append(epoch_train_loss)\n",
    "    train_accuracies.append(epoch_train_accuracy)\n",
    "    validation_losses.append(epoch_validation_loss)\n",
    "    validation_accuracies.append(epoch_validation_accuracy)\n",
    "            \n",
    "print(\"Finished Training\")\n",
    "time_elapsed = time.time() - since\n",
    "print(\n",
    "    'Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60\n",
    "    )\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward, input x.size():  torch.Size([32, 3, 100, 100])\n",
      "forward, x.size() after self.pool(F.relu(self.conv2_bn(self.conv1(x)))):  torch.Size([32, 32, 48, 48])\n",
      "forward, x.size() after self.pool2(F.relu(self.conv2(x))):  torch.Size([32, 64, 16, 16])\n",
      "forward, x.size() after x.view(-1, 64 * 4 * 4 * 16):  torch.Size([32, 16384])\n",
      "forward, x.size() after F.relu(self.fc1(x)):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.dropout(x):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.fc2(x):  torch.Size([32, 1])\n",
      "forward, x.size() after self.sigmoid(x):  torch.Size([32, 1])\n",
      "forward, input x.size():  torch.Size([32, 3, 100, 100])\n",
      "forward, x.size() after self.pool(F.relu(self.conv2_bn(self.conv1(x)))):  torch.Size([32, 32, 48, 48])\n",
      "forward, x.size() after self.pool2(F.relu(self.conv2(x))):  torch.Size([32, 64, 16, 16])\n",
      "forward, x.size() after x.view(-1, 64 * 4 * 4 * 16):  torch.Size([32, 16384])\n",
      "forward, x.size() after F.relu(self.fc1(x)):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.dropout(x):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.fc2(x):  torch.Size([32, 1])\n",
      "forward, x.size() after self.sigmoid(x):  torch.Size([32, 1])\n",
      "forward, input x.size():  torch.Size([32, 3, 100, 100])\n",
      "forward, x.size() after self.pool(F.relu(self.conv2_bn(self.conv1(x)))):  torch.Size([32, 32, 48, 48])\n",
      "forward, x.size() after self.pool2(F.relu(self.conv2(x))):  torch.Size([32, 64, 16, 16])\n",
      "forward, x.size() after x.view(-1, 64 * 4 * 4 * 16):  torch.Size([32, 16384])\n",
      "forward, x.size() after F.relu(self.fc1(x)):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.dropout(x):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.fc2(x):  torch.Size([32, 1])\n",
      "forward, x.size() after self.sigmoid(x):  torch.Size([32, 1])\n",
      "forward, input x.size():  torch.Size([32, 3, 100, 100])\n",
      "forward, x.size() after self.pool(F.relu(self.conv2_bn(self.conv1(x)))):  torch.Size([32, 32, 48, 48])\n",
      "forward, x.size() after self.pool2(F.relu(self.conv2(x))):  torch.Size([32, 64, 16, 16])\n",
      "forward, x.size() after x.view(-1, 64 * 4 * 4 * 16):  torch.Size([32, 16384])\n",
      "forward, x.size() after F.relu(self.fc1(x)):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.dropout(x):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.fc2(x):  torch.Size([32, 1])\n",
      "forward, x.size() after self.sigmoid(x):  torch.Size([32, 1])\n",
      "forward, input x.size():  torch.Size([32, 3, 100, 100])\n",
      "forward, x.size() after self.pool(F.relu(self.conv2_bn(self.conv1(x)))):  torch.Size([32, 32, 48, 48])\n",
      "forward, x.size() after self.pool2(F.relu(self.conv2(x))):  torch.Size([32, 64, 16, 16])\n",
      "forward, x.size() after x.view(-1, 64 * 4 * 4 * 16):  torch.Size([32, 16384])\n",
      "forward, x.size() after F.relu(self.fc1(x)):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.dropout(x):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.fc2(x):  torch.Size([32, 1])\n",
      "forward, x.size() after self.sigmoid(x):  torch.Size([32, 1])\n",
      "forward, input x.size():  torch.Size([32, 3, 100, 100])\n",
      "forward, x.size() after self.pool(F.relu(self.conv2_bn(self.conv1(x)))):  torch.Size([32, 32, 48, 48])\n",
      "forward, x.size() after self.pool2(F.relu(self.conv2(x))):  torch.Size([32, 64, 16, 16])\n",
      "forward, x.size() after x.view(-1, 64 * 4 * 4 * 16):  torch.Size([32, 16384])\n",
      "forward, x.size() after F.relu(self.fc1(x)):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.dropout(x):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.fc2(x):  torch.Size([32, 1])\n",
      "forward, x.size() after self.sigmoid(x):  torch.Size([32, 1])\n",
      "forward, input x.size():  torch.Size([32, 3, 100, 100])\n",
      "forward, x.size() after self.pool(F.relu(self.conv2_bn(self.conv1(x)))):  torch.Size([32, 32, 48, 48])\n",
      "forward, x.size() after self.pool2(F.relu(self.conv2(x))):  torch.Size([32, 64, 16, 16])\n",
      "forward, x.size() after x.view(-1, 64 * 4 * 4 * 16):  torch.Size([32, 16384])\n",
      "forward, x.size() after F.relu(self.fc1(x)):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.dropout(x):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.fc2(x):  torch.Size([32, 1])\n",
      "forward, x.size() after self.sigmoid(x):  torch.Size([32, 1])\n",
      "forward, input x.size():  torch.Size([32, 3, 100, 100])\n",
      "forward, x.size() after self.pool(F.relu(self.conv2_bn(self.conv1(x)))):  torch.Size([32, 32, 48, 48])\n",
      "forward, x.size() after self.pool2(F.relu(self.conv2(x))):  torch.Size([32, 64, 16, 16])\n",
      "forward, x.size() after x.view(-1, 64 * 4 * 4 * 16):  torch.Size([32, 16384])\n",
      "forward, x.size() after F.relu(self.fc1(x)):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.dropout(x):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.fc2(x):  torch.Size([32, 1])\n",
      "forward, x.size() after self.sigmoid(x):  torch.Size([32, 1])\n",
      "forward, input x.size():  torch.Size([32, 3, 100, 100])\n",
      "forward, x.size() after self.pool(F.relu(self.conv2_bn(self.conv1(x)))):  torch.Size([32, 32, 48, 48])\n",
      "forward, x.size() after self.pool2(F.relu(self.conv2(x))):  torch.Size([32, 64, 16, 16])\n",
      "forward, x.size() after x.view(-1, 64 * 4 * 4 * 16):  torch.Size([32, 16384])\n",
      "forward, x.size() after F.relu(self.fc1(x)):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.dropout(x):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.fc2(x):  torch.Size([32, 1])\n",
      "forward, x.size() after self.sigmoid(x):  torch.Size([32, 1])\n",
      "forward, input x.size():  torch.Size([32, 3, 100, 100])\n",
      "forward, x.size() after self.pool(F.relu(self.conv2_bn(self.conv1(x)))):  torch.Size([32, 32, 48, 48])\n",
      "forward, x.size() after self.pool2(F.relu(self.conv2(x))):  torch.Size([32, 64, 16, 16])\n",
      "forward, x.size() after x.view(-1, 64 * 4 * 4 * 16):  torch.Size([32, 16384])\n",
      "forward, x.size() after F.relu(self.fc1(x)):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.dropout(x):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.fc2(x):  torch.Size([32, 1])\n",
      "forward, x.size() after self.sigmoid(x):  torch.Size([32, 1])\n",
      "forward, input x.size():  torch.Size([32, 3, 100, 100])\n",
      "forward, x.size() after self.pool(F.relu(self.conv2_bn(self.conv1(x)))):  torch.Size([32, 32, 48, 48])\n",
      "forward, x.size() after self.pool2(F.relu(self.conv2(x))):  torch.Size([32, 64, 16, 16])\n",
      "forward, x.size() after x.view(-1, 64 * 4 * 4 * 16):  torch.Size([32, 16384])\n",
      "forward, x.size() after F.relu(self.fc1(x)):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.dropout(x):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.fc2(x):  torch.Size([32, 1])\n",
      "forward, x.size() after self.sigmoid(x):  torch.Size([32, 1])\n",
      "forward, input x.size():  torch.Size([32, 3, 100, 100])\n",
      "forward, x.size() after self.pool(F.relu(self.conv2_bn(self.conv1(x)))):  torch.Size([32, 32, 48, 48])\n",
      "forward, x.size() after self.pool2(F.relu(self.conv2(x))):  torch.Size([32, 64, 16, 16])\n",
      "forward, x.size() after x.view(-1, 64 * 4 * 4 * 16):  torch.Size([32, 16384])\n",
      "forward, x.size() after F.relu(self.fc1(x)):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.dropout(x):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.fc2(x):  torch.Size([32, 1])\n",
      "forward, x.size() after self.sigmoid(x):  torch.Size([32, 1])\n",
      "forward, input x.size():  torch.Size([32, 3, 100, 100])\n",
      "forward, x.size() after self.pool(F.relu(self.conv2_bn(self.conv1(x)))):  torch.Size([32, 32, 48, 48])\n",
      "forward, x.size() after self.pool2(F.relu(self.conv2(x))):  torch.Size([32, 64, 16, 16])\n",
      "forward, x.size() after x.view(-1, 64 * 4 * 4 * 16):  torch.Size([32, 16384])\n",
      "forward, x.size() after F.relu(self.fc1(x)):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.dropout(x):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.fc2(x):  torch.Size([32, 1])\n",
      "forward, x.size() after self.sigmoid(x):  torch.Size([32, 1])\n",
      "forward, input x.size():  torch.Size([32, 3, 100, 100])\n",
      "forward, x.size() after self.pool(F.relu(self.conv2_bn(self.conv1(x)))):  torch.Size([32, 32, 48, 48])\n",
      "forward, x.size() after self.pool2(F.relu(self.conv2(x))):  torch.Size([32, 64, 16, 16])\n",
      "forward, x.size() after x.view(-1, 64 * 4 * 4 * 16):  torch.Size([32, 16384])\n",
      "forward, x.size() after F.relu(self.fc1(x)):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.dropout(x):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.fc2(x):  torch.Size([32, 1])\n",
      "forward, x.size() after self.sigmoid(x):  torch.Size([32, 1])\n",
      "forward, input x.size():  torch.Size([32, 3, 100, 100])\n",
      "forward, x.size() after self.pool(F.relu(self.conv2_bn(self.conv1(x)))):  torch.Size([32, 32, 48, 48])\n",
      "forward, x.size() after self.pool2(F.relu(self.conv2(x))):  torch.Size([32, 64, 16, 16])\n",
      "forward, x.size() after x.view(-1, 64 * 4 * 4 * 16):  torch.Size([32, 16384])\n",
      "forward, x.size() after F.relu(self.fc1(x)):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.dropout(x):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.fc2(x):  torch.Size([32, 1])\n",
      "forward, x.size() after self.sigmoid(x):  torch.Size([32, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward, input x.size():  torch.Size([32, 3, 100, 100])\n",
      "forward, x.size() after self.pool(F.relu(self.conv2_bn(self.conv1(x)))):  torch.Size([32, 32, 48, 48])\n",
      "forward, x.size() after self.pool2(F.relu(self.conv2(x))):  torch.Size([32, 64, 16, 16])\n",
      "forward, x.size() after x.view(-1, 64 * 4 * 4 * 16):  torch.Size([32, 16384])\n",
      "forward, x.size() after F.relu(self.fc1(x)):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.dropout(x):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.fc2(x):  torch.Size([32, 1])\n",
      "forward, x.size() after self.sigmoid(x):  torch.Size([32, 1])\n",
      "forward, input x.size():  torch.Size([32, 3, 100, 100])\n",
      "forward, x.size() after self.pool(F.relu(self.conv2_bn(self.conv1(x)))):  torch.Size([32, 32, 48, 48])\n",
      "forward, x.size() after self.pool2(F.relu(self.conv2(x))):  torch.Size([32, 64, 16, 16])\n",
      "forward, x.size() after x.view(-1, 64 * 4 * 4 * 16):  torch.Size([32, 16384])\n",
      "forward, x.size() after F.relu(self.fc1(x)):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.dropout(x):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.fc2(x):  torch.Size([32, 1])\n",
      "forward, x.size() after self.sigmoid(x):  torch.Size([32, 1])\n",
      "forward, input x.size():  torch.Size([32, 3, 100, 100])\n",
      "forward, x.size() after self.pool(F.relu(self.conv2_bn(self.conv1(x)))):  torch.Size([32, 32, 48, 48])\n",
      "forward, x.size() after self.pool2(F.relu(self.conv2(x))):  torch.Size([32, 64, 16, 16])\n",
      "forward, x.size() after x.view(-1, 64 * 4 * 4 * 16):  torch.Size([32, 16384])\n",
      "forward, x.size() after F.relu(self.fc1(x)):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.dropout(x):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.fc2(x):  torch.Size([32, 1])\n",
      "forward, x.size() after self.sigmoid(x):  torch.Size([32, 1])\n",
      "forward, input x.size():  torch.Size([32, 3, 100, 100])\n",
      "forward, x.size() after self.pool(F.relu(self.conv2_bn(self.conv1(x)))):  torch.Size([32, 32, 48, 48])\n",
      "forward, x.size() after self.pool2(F.relu(self.conv2(x))):  torch.Size([32, 64, 16, 16])\n",
      "forward, x.size() after x.view(-1, 64 * 4 * 4 * 16):  torch.Size([32, 16384])\n",
      "forward, x.size() after F.relu(self.fc1(x)):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.dropout(x):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.fc2(x):  torch.Size([32, 1])\n",
      "forward, x.size() after self.sigmoid(x):  torch.Size([32, 1])\n",
      "forward, input x.size():  torch.Size([32, 3, 100, 100])\n",
      "forward, x.size() after self.pool(F.relu(self.conv2_bn(self.conv1(x)))):  torch.Size([32, 32, 48, 48])\n",
      "forward, x.size() after self.pool2(F.relu(self.conv2(x))):  torch.Size([32, 64, 16, 16])\n",
      "forward, x.size() after x.view(-1, 64 * 4 * 4 * 16):  torch.Size([32, 16384])\n",
      "forward, x.size() after F.relu(self.fc1(x)):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.dropout(x):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.fc2(x):  torch.Size([32, 1])\n",
      "forward, x.size() after self.sigmoid(x):  torch.Size([32, 1])\n",
      "forward, input x.size():  torch.Size([32, 3, 100, 100])\n",
      "forward, x.size() after self.pool(F.relu(self.conv2_bn(self.conv1(x)))):  torch.Size([32, 32, 48, 48])\n",
      "forward, x.size() after self.pool2(F.relu(self.conv2(x))):  torch.Size([32, 64, 16, 16])\n",
      "forward, x.size() after x.view(-1, 64 * 4 * 4 * 16):  torch.Size([32, 16384])\n",
      "forward, x.size() after F.relu(self.fc1(x)):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.dropout(x):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.fc2(x):  torch.Size([32, 1])\n",
      "forward, x.size() after self.sigmoid(x):  torch.Size([32, 1])\n",
      "forward, input x.size():  torch.Size([32, 3, 100, 100])\n",
      "forward, x.size() after self.pool(F.relu(self.conv2_bn(self.conv1(x)))):  torch.Size([32, 32, 48, 48])\n",
      "forward, x.size() after self.pool2(F.relu(self.conv2(x))):  torch.Size([32, 64, 16, 16])\n",
      "forward, x.size() after x.view(-1, 64 * 4 * 4 * 16):  torch.Size([32, 16384])\n",
      "forward, x.size() after F.relu(self.fc1(x)):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.dropout(x):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.fc2(x):  torch.Size([32, 1])\n",
      "forward, x.size() after self.sigmoid(x):  torch.Size([32, 1])\n",
      "forward, input x.size():  torch.Size([32, 3, 100, 100])\n",
      "forward, x.size() after self.pool(F.relu(self.conv2_bn(self.conv1(x)))):  torch.Size([32, 32, 48, 48])\n",
      "forward, x.size() after self.pool2(F.relu(self.conv2(x))):  torch.Size([32, 64, 16, 16])\n",
      "forward, x.size() after x.view(-1, 64 * 4 * 4 * 16):  torch.Size([32, 16384])\n",
      "forward, x.size() after F.relu(self.fc1(x)):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.dropout(x):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.fc2(x):  torch.Size([32, 1])\n",
      "forward, x.size() after self.sigmoid(x):  torch.Size([32, 1])\n",
      "forward, input x.size():  torch.Size([32, 3, 100, 100])\n",
      "forward, x.size() after self.pool(F.relu(self.conv2_bn(self.conv1(x)))):  torch.Size([32, 32, 48, 48])\n",
      "forward, x.size() after self.pool2(F.relu(self.conv2(x))):  torch.Size([32, 64, 16, 16])\n",
      "forward, x.size() after x.view(-1, 64 * 4 * 4 * 16):  torch.Size([32, 16384])\n",
      "forward, x.size() after F.relu(self.fc1(x)):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.dropout(x):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.fc2(x):  torch.Size([32, 1])\n",
      "forward, x.size() after self.sigmoid(x):  torch.Size([32, 1])\n",
      "forward, input x.size():  torch.Size([32, 3, 100, 100])\n",
      "forward, x.size() after self.pool(F.relu(self.conv2_bn(self.conv1(x)))):  torch.Size([32, 32, 48, 48])\n",
      "forward, x.size() after self.pool2(F.relu(self.conv2(x))):  torch.Size([32, 64, 16, 16])\n",
      "forward, x.size() after x.view(-1, 64 * 4 * 4 * 16):  torch.Size([32, 16384])\n",
      "forward, x.size() after F.relu(self.fc1(x)):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.dropout(x):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.fc2(x):  torch.Size([32, 1])\n",
      "forward, x.size() after self.sigmoid(x):  torch.Size([32, 1])\n",
      "forward, input x.size():  torch.Size([32, 3, 100, 100])\n",
      "forward, x.size() after self.pool(F.relu(self.conv2_bn(self.conv1(x)))):  torch.Size([32, 32, 48, 48])\n",
      "forward, x.size() after self.pool2(F.relu(self.conv2(x))):  torch.Size([32, 64, 16, 16])\n",
      "forward, x.size() after x.view(-1, 64 * 4 * 4 * 16):  torch.Size([32, 16384])\n",
      "forward, x.size() after F.relu(self.fc1(x)):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.dropout(x):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.fc2(x):  torch.Size([32, 1])\n",
      "forward, x.size() after self.sigmoid(x):  torch.Size([32, 1])\n",
      "forward, input x.size():  torch.Size([32, 3, 100, 100])\n",
      "forward, x.size() after self.pool(F.relu(self.conv2_bn(self.conv1(x)))):  torch.Size([32, 32, 48, 48])\n",
      "forward, x.size() after self.pool2(F.relu(self.conv2(x))):  torch.Size([32, 64, 16, 16])\n",
      "forward, x.size() after x.view(-1, 64 * 4 * 4 * 16):  torch.Size([32, 16384])\n",
      "forward, x.size() after F.relu(self.fc1(x)):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.dropout(x):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.fc2(x):  torch.Size([32, 1])\n",
      "forward, x.size() after self.sigmoid(x):  torch.Size([32, 1])\n",
      "forward, input x.size():  torch.Size([32, 3, 100, 100])\n",
      "forward, x.size() after self.pool(F.relu(self.conv2_bn(self.conv1(x)))):  torch.Size([32, 32, 48, 48])\n",
      "forward, x.size() after self.pool2(F.relu(self.conv2(x))):  torch.Size([32, 64, 16, 16])\n",
      "forward, x.size() after x.view(-1, 64 * 4 * 4 * 16):  torch.Size([32, 16384])\n",
      "forward, x.size() after F.relu(self.fc1(x)):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.dropout(x):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.fc2(x):  torch.Size([32, 1])\n",
      "forward, x.size() after self.sigmoid(x):  torch.Size([32, 1])\n",
      "forward, input x.size():  torch.Size([32, 3, 100, 100])\n",
      "forward, x.size() after self.pool(F.relu(self.conv2_bn(self.conv1(x)))):  torch.Size([32, 32, 48, 48])\n",
      "forward, x.size() after self.pool2(F.relu(self.conv2(x))):  torch.Size([32, 64, 16, 16])\n",
      "forward, x.size() after x.view(-1, 64 * 4 * 4 * 16):  torch.Size([32, 16384])\n",
      "forward, x.size() after F.relu(self.fc1(x)):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.dropout(x):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.fc2(x):  torch.Size([32, 1])\n",
      "forward, x.size() after self.sigmoid(x):  torch.Size([32, 1])\n",
      "forward, input x.size():  torch.Size([32, 3, 100, 100])\n",
      "forward, x.size() after self.pool(F.relu(self.conv2_bn(self.conv1(x)))):  torch.Size([32, 32, 48, 48])\n",
      "forward, x.size() after self.pool2(F.relu(self.conv2(x))):  torch.Size([32, 64, 16, 16])\n",
      "forward, x.size() after x.view(-1, 64 * 4 * 4 * 16):  torch.Size([32, 16384])\n",
      "forward, x.size() after F.relu(self.fc1(x)):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.dropout(x):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.fc2(x):  torch.Size([32, 1])\n",
      "forward, x.size() after self.sigmoid(x):  torch.Size([32, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward, input x.size():  torch.Size([32, 3, 100, 100])\n",
      "forward, x.size() after self.pool(F.relu(self.conv2_bn(self.conv1(x)))):  torch.Size([32, 32, 48, 48])\n",
      "forward, x.size() after self.pool2(F.relu(self.conv2(x))):  torch.Size([32, 64, 16, 16])\n",
      "forward, x.size() after x.view(-1, 64 * 4 * 4 * 16):  torch.Size([32, 16384])\n",
      "forward, x.size() after F.relu(self.fc1(x)):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.dropout(x):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.fc2(x):  torch.Size([32, 1])\n",
      "forward, x.size() after self.sigmoid(x):  torch.Size([32, 1])\n",
      "forward, input x.size():  torch.Size([32, 3, 100, 100])\n",
      "forward, x.size() after self.pool(F.relu(self.conv2_bn(self.conv1(x)))):  torch.Size([32, 32, 48, 48])\n",
      "forward, x.size() after self.pool2(F.relu(self.conv2(x))):  torch.Size([32, 64, 16, 16])\n",
      "forward, x.size() after x.view(-1, 64 * 4 * 4 * 16):  torch.Size([32, 16384])\n",
      "forward, x.size() after F.relu(self.fc1(x)):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.dropout(x):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.fc2(x):  torch.Size([32, 1])\n",
      "forward, x.size() after self.sigmoid(x):  torch.Size([32, 1])\n",
      "forward, input x.size():  torch.Size([32, 3, 100, 100])\n",
      "forward, x.size() after self.pool(F.relu(self.conv2_bn(self.conv1(x)))):  torch.Size([32, 32, 48, 48])\n",
      "forward, x.size() after self.pool2(F.relu(self.conv2(x))):  torch.Size([32, 64, 16, 16])\n",
      "forward, x.size() after x.view(-1, 64 * 4 * 4 * 16):  torch.Size([32, 16384])\n",
      "forward, x.size() after F.relu(self.fc1(x)):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.dropout(x):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.fc2(x):  torch.Size([32, 1])\n",
      "forward, x.size() after self.sigmoid(x):  torch.Size([32, 1])\n",
      "forward, input x.size():  torch.Size([32, 3, 100, 100])\n",
      "forward, x.size() after self.pool(F.relu(self.conv2_bn(self.conv1(x)))):  torch.Size([32, 32, 48, 48])\n",
      "forward, x.size() after self.pool2(F.relu(self.conv2(x))):  torch.Size([32, 64, 16, 16])\n",
      "forward, x.size() after x.view(-1, 64 * 4 * 4 * 16):  torch.Size([32, 16384])\n",
      "forward, x.size() after F.relu(self.fc1(x)):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.dropout(x):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.fc2(x):  torch.Size([32, 1])\n",
      "forward, x.size() after self.sigmoid(x):  torch.Size([32, 1])\n",
      "forward, input x.size():  torch.Size([32, 3, 100, 100])\n",
      "forward, x.size() after self.pool(F.relu(self.conv2_bn(self.conv1(x)))):  torch.Size([32, 32, 48, 48])\n",
      "forward, x.size() after self.pool2(F.relu(self.conv2(x))):  torch.Size([32, 64, 16, 16])\n",
      "forward, x.size() after x.view(-1, 64 * 4 * 4 * 16):  torch.Size([32, 16384])\n",
      "forward, x.size() after F.relu(self.fc1(x)):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.dropout(x):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.fc2(x):  torch.Size([32, 1])\n",
      "forward, x.size() after self.sigmoid(x):  torch.Size([32, 1])\n",
      "forward, input x.size():  torch.Size([32, 3, 100, 100])\n",
      "forward, x.size() after self.pool(F.relu(self.conv2_bn(self.conv1(x)))):  torch.Size([32, 32, 48, 48])\n",
      "forward, x.size() after self.pool2(F.relu(self.conv2(x))):  torch.Size([32, 64, 16, 16])\n",
      "forward, x.size() after x.view(-1, 64 * 4 * 4 * 16):  torch.Size([32, 16384])\n",
      "forward, x.size() after F.relu(self.fc1(x)):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.dropout(x):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.fc2(x):  torch.Size([32, 1])\n",
      "forward, x.size() after self.sigmoid(x):  torch.Size([32, 1])\n",
      "forward, input x.size():  torch.Size([32, 3, 100, 100])\n",
      "forward, x.size() after self.pool(F.relu(self.conv2_bn(self.conv1(x)))):  torch.Size([32, 32, 48, 48])\n",
      "forward, x.size() after self.pool2(F.relu(self.conv2(x))):  torch.Size([32, 64, 16, 16])\n",
      "forward, x.size() after x.view(-1, 64 * 4 * 4 * 16):  torch.Size([32, 16384])\n",
      "forward, x.size() after F.relu(self.fc1(x)):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.dropout(x):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.fc2(x):  torch.Size([32, 1])\n",
      "forward, x.size() after self.sigmoid(x):  torch.Size([32, 1])\n",
      "forward, input x.size():  torch.Size([32, 3, 100, 100])\n",
      "forward, x.size() after self.pool(F.relu(self.conv2_bn(self.conv1(x)))):  torch.Size([32, 32, 48, 48])\n",
      "forward, x.size() after self.pool2(F.relu(self.conv2(x))):  torch.Size([32, 64, 16, 16])\n",
      "forward, x.size() after x.view(-1, 64 * 4 * 4 * 16):  torch.Size([32, 16384])\n",
      "forward, x.size() after F.relu(self.fc1(x)):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.dropout(x):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.fc2(x):  torch.Size([32, 1])\n",
      "forward, x.size() after self.sigmoid(x):  torch.Size([32, 1])\n",
      "forward, input x.size():  torch.Size([32, 3, 100, 100])\n",
      "forward, x.size() after self.pool(F.relu(self.conv2_bn(self.conv1(x)))):  torch.Size([32, 32, 48, 48])\n",
      "forward, x.size() after self.pool2(F.relu(self.conv2(x))):  torch.Size([32, 64, 16, 16])\n",
      "forward, x.size() after x.view(-1, 64 * 4 * 4 * 16):  torch.Size([32, 16384])\n",
      "forward, x.size() after F.relu(self.fc1(x)):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.dropout(x):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.fc2(x):  torch.Size([32, 1])\n",
      "forward, x.size() after self.sigmoid(x):  torch.Size([32, 1])\n",
      "forward, input x.size():  torch.Size([32, 3, 100, 100])\n",
      "forward, x.size() after self.pool(F.relu(self.conv2_bn(self.conv1(x)))):  torch.Size([32, 32, 48, 48])\n",
      "forward, x.size() after self.pool2(F.relu(self.conv2(x))):  torch.Size([32, 64, 16, 16])\n",
      "forward, x.size() after x.view(-1, 64 * 4 * 4 * 16):  torch.Size([32, 16384])\n",
      "forward, x.size() after F.relu(self.fc1(x)):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.dropout(x):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.fc2(x):  torch.Size([32, 1])\n",
      "forward, x.size() after self.sigmoid(x):  torch.Size([32, 1])\n",
      "forward, input x.size():  torch.Size([32, 3, 100, 100])\n",
      "forward, x.size() after self.pool(F.relu(self.conv2_bn(self.conv1(x)))):  torch.Size([32, 32, 48, 48])\n",
      "forward, x.size() after self.pool2(F.relu(self.conv2(x))):  torch.Size([32, 64, 16, 16])\n",
      "forward, x.size() after x.view(-1, 64 * 4 * 4 * 16):  torch.Size([32, 16384])\n",
      "forward, x.size() after F.relu(self.fc1(x)):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.dropout(x):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.fc2(x):  torch.Size([32, 1])\n",
      "forward, x.size() after self.sigmoid(x):  torch.Size([32, 1])\n",
      "forward, input x.size():  torch.Size([32, 3, 100, 100])\n",
      "forward, x.size() after self.pool(F.relu(self.conv2_bn(self.conv1(x)))):  torch.Size([32, 32, 48, 48])\n",
      "forward, x.size() after self.pool2(F.relu(self.conv2(x))):  torch.Size([32, 64, 16, 16])\n",
      "forward, x.size() after x.view(-1, 64 * 4 * 4 * 16):  torch.Size([32, 16384])\n",
      "forward, x.size() after F.relu(self.fc1(x)):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.dropout(x):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.fc2(x):  torch.Size([32, 1])\n",
      "forward, x.size() after self.sigmoid(x):  torch.Size([32, 1])\n",
      "forward, input x.size():  torch.Size([32, 3, 100, 100])\n",
      "forward, x.size() after self.pool(F.relu(self.conv2_bn(self.conv1(x)))):  torch.Size([32, 32, 48, 48])\n",
      "forward, x.size() after self.pool2(F.relu(self.conv2(x))):  torch.Size([32, 64, 16, 16])\n",
      "forward, x.size() after x.view(-1, 64 * 4 * 4 * 16):  torch.Size([32, 16384])\n",
      "forward, x.size() after F.relu(self.fc1(x)):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.dropout(x):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.fc2(x):  torch.Size([32, 1])\n",
      "forward, x.size() after self.sigmoid(x):  torch.Size([32, 1])\n",
      "forward, input x.size():  torch.Size([32, 3, 100, 100])\n",
      "forward, x.size() after self.pool(F.relu(self.conv2_bn(self.conv1(x)))):  torch.Size([32, 32, 48, 48])\n",
      "forward, x.size() after self.pool2(F.relu(self.conv2(x))):  torch.Size([32, 64, 16, 16])\n",
      "forward, x.size() after x.view(-1, 64 * 4 * 4 * 16):  torch.Size([32, 16384])\n",
      "forward, x.size() after F.relu(self.fc1(x)):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.dropout(x):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.fc2(x):  torch.Size([32, 1])\n",
      "forward, x.size() after self.sigmoid(x):  torch.Size([32, 1])\n",
      "forward, input x.size():  torch.Size([32, 3, 100, 100])\n",
      "forward, x.size() after self.pool(F.relu(self.conv2_bn(self.conv1(x)))):  torch.Size([32, 32, 48, 48])\n",
      "forward, x.size() after self.pool2(F.relu(self.conv2(x))):  torch.Size([32, 64, 16, 16])\n",
      "forward, x.size() after x.view(-1, 64 * 4 * 4 * 16):  torch.Size([32, 16384])\n",
      "forward, x.size() after F.relu(self.fc1(x)):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.dropout(x):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.fc2(x):  torch.Size([32, 1])\n",
      "forward, x.size() after self.sigmoid(x):  torch.Size([32, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward, input x.size():  torch.Size([32, 3, 100, 100])\n",
      "forward, x.size() after self.pool(F.relu(self.conv2_bn(self.conv1(x)))):  torch.Size([32, 32, 48, 48])\n",
      "forward, x.size() after self.pool2(F.relu(self.conv2(x))):  torch.Size([32, 64, 16, 16])\n",
      "forward, x.size() after x.view(-1, 64 * 4 * 4 * 16):  torch.Size([32, 16384])\n",
      "forward, x.size() after F.relu(self.fc1(x)):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.dropout(x):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.fc2(x):  torch.Size([32, 1])\n",
      "forward, x.size() after self.sigmoid(x):  torch.Size([32, 1])\n",
      "forward, input x.size():  torch.Size([32, 3, 100, 100])\n",
      "forward, x.size() after self.pool(F.relu(self.conv2_bn(self.conv1(x)))):  torch.Size([32, 32, 48, 48])\n",
      "forward, x.size() after self.pool2(F.relu(self.conv2(x))):  torch.Size([32, 64, 16, 16])\n",
      "forward, x.size() after x.view(-1, 64 * 4 * 4 * 16):  torch.Size([32, 16384])\n",
      "forward, x.size() after F.relu(self.fc1(x)):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.dropout(x):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.fc2(x):  torch.Size([32, 1])\n",
      "forward, x.size() after self.sigmoid(x):  torch.Size([32, 1])\n",
      "forward, input x.size():  torch.Size([32, 3, 100, 100])\n",
      "forward, x.size() after self.pool(F.relu(self.conv2_bn(self.conv1(x)))):  torch.Size([32, 32, 48, 48])\n",
      "forward, x.size() after self.pool2(F.relu(self.conv2(x))):  torch.Size([32, 64, 16, 16])\n",
      "forward, x.size() after x.view(-1, 64 * 4 * 4 * 16):  torch.Size([32, 16384])\n",
      "forward, x.size() after F.relu(self.fc1(x)):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.dropout(x):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.fc2(x):  torch.Size([32, 1])\n",
      "forward, x.size() after self.sigmoid(x):  torch.Size([32, 1])\n",
      "forward, input x.size():  torch.Size([32, 3, 100, 100])\n",
      "forward, x.size() after self.pool(F.relu(self.conv2_bn(self.conv1(x)))):  torch.Size([32, 32, 48, 48])\n",
      "forward, x.size() after self.pool2(F.relu(self.conv2(x))):  torch.Size([32, 64, 16, 16])\n",
      "forward, x.size() after x.view(-1, 64 * 4 * 4 * 16):  torch.Size([32, 16384])\n",
      "forward, x.size() after F.relu(self.fc1(x)):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.dropout(x):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.fc2(x):  torch.Size([32, 1])\n",
      "forward, x.size() after self.sigmoid(x):  torch.Size([32, 1])\n",
      "forward, input x.size():  torch.Size([32, 3, 100, 100])\n",
      "forward, x.size() after self.pool(F.relu(self.conv2_bn(self.conv1(x)))):  torch.Size([32, 32, 48, 48])\n",
      "forward, x.size() after self.pool2(F.relu(self.conv2(x))):  torch.Size([32, 64, 16, 16])\n",
      "forward, x.size() after x.view(-1, 64 * 4 * 4 * 16):  torch.Size([32, 16384])\n",
      "forward, x.size() after F.relu(self.fc1(x)):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.dropout(x):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.fc2(x):  torch.Size([32, 1])\n",
      "forward, x.size() after self.sigmoid(x):  torch.Size([32, 1])\n",
      "forward, input x.size():  torch.Size([32, 3, 100, 100])\n",
      "forward, x.size() after self.pool(F.relu(self.conv2_bn(self.conv1(x)))):  torch.Size([32, 32, 48, 48])\n",
      "forward, x.size() after self.pool2(F.relu(self.conv2(x))):  torch.Size([32, 64, 16, 16])\n",
      "forward, x.size() after x.view(-1, 64 * 4 * 4 * 16):  torch.Size([32, 16384])\n",
      "forward, x.size() after F.relu(self.fc1(x)):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.dropout(x):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.fc2(x):  torch.Size([32, 1])\n",
      "forward, x.size() after self.sigmoid(x):  torch.Size([32, 1])\n",
      "forward, input x.size():  torch.Size([32, 3, 100, 100])\n",
      "forward, x.size() after self.pool(F.relu(self.conv2_bn(self.conv1(x)))):  torch.Size([32, 32, 48, 48])\n",
      "forward, x.size() after self.pool2(F.relu(self.conv2(x))):  torch.Size([32, 64, 16, 16])\n",
      "forward, x.size() after x.view(-1, 64 * 4 * 4 * 16):  torch.Size([32, 16384])\n",
      "forward, x.size() after F.relu(self.fc1(x)):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.dropout(x):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.fc2(x):  torch.Size([32, 1])\n",
      "forward, x.size() after self.sigmoid(x):  torch.Size([32, 1])\n",
      "forward, input x.size():  torch.Size([32, 3, 100, 100])\n",
      "forward, x.size() after self.pool(F.relu(self.conv2_bn(self.conv1(x)))):  torch.Size([32, 32, 48, 48])\n",
      "forward, x.size() after self.pool2(F.relu(self.conv2(x))):  torch.Size([32, 64, 16, 16])\n",
      "forward, x.size() after x.view(-1, 64 * 4 * 4 * 16):  torch.Size([32, 16384])\n",
      "forward, x.size() after F.relu(self.fc1(x)):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.dropout(x):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.fc2(x):  torch.Size([32, 1])\n",
      "forward, x.size() after self.sigmoid(x):  torch.Size([32, 1])\n",
      "forward, input x.size():  torch.Size([32, 3, 100, 100])\n",
      "forward, x.size() after self.pool(F.relu(self.conv2_bn(self.conv1(x)))):  torch.Size([32, 32, 48, 48])\n",
      "forward, x.size() after self.pool2(F.relu(self.conv2(x))):  torch.Size([32, 64, 16, 16])\n",
      "forward, x.size() after x.view(-1, 64 * 4 * 4 * 16):  torch.Size([32, 16384])\n",
      "forward, x.size() after F.relu(self.fc1(x)):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.dropout(x):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.fc2(x):  torch.Size([32, 1])\n",
      "forward, x.size() after self.sigmoid(x):  torch.Size([32, 1])\n",
      "forward, input x.size():  torch.Size([32, 3, 100, 100])\n",
      "forward, x.size() after self.pool(F.relu(self.conv2_bn(self.conv1(x)))):  torch.Size([32, 32, 48, 48])\n",
      "forward, x.size() after self.pool2(F.relu(self.conv2(x))):  torch.Size([32, 64, 16, 16])\n",
      "forward, x.size() after x.view(-1, 64 * 4 * 4 * 16):  torch.Size([32, 16384])\n",
      "forward, x.size() after F.relu(self.fc1(x)):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.dropout(x):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.fc2(x):  torch.Size([32, 1])\n",
      "forward, x.size() after self.sigmoid(x):  torch.Size([32, 1])\n",
      "forward, input x.size():  torch.Size([32, 3, 100, 100])\n",
      "forward, x.size() after self.pool(F.relu(self.conv2_bn(self.conv1(x)))):  torch.Size([32, 32, 48, 48])\n",
      "forward, x.size() after self.pool2(F.relu(self.conv2(x))):  torch.Size([32, 64, 16, 16])\n",
      "forward, x.size() after x.view(-1, 64 * 4 * 4 * 16):  torch.Size([32, 16384])\n",
      "forward, x.size() after F.relu(self.fc1(x)):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.dropout(x):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.fc2(x):  torch.Size([32, 1])\n",
      "forward, x.size() after self.sigmoid(x):  torch.Size([32, 1])\n",
      "forward, input x.size():  torch.Size([32, 3, 100, 100])\n",
      "forward, x.size() after self.pool(F.relu(self.conv2_bn(self.conv1(x)))):  torch.Size([32, 32, 48, 48])\n",
      "forward, x.size() after self.pool2(F.relu(self.conv2(x))):  torch.Size([32, 64, 16, 16])\n",
      "forward, x.size() after x.view(-1, 64 * 4 * 4 * 16):  torch.Size([32, 16384])\n",
      "forward, x.size() after F.relu(self.fc1(x)):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.dropout(x):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.fc2(x):  torch.Size([32, 1])\n",
      "forward, x.size() after self.sigmoid(x):  torch.Size([32, 1])\n",
      "forward, input x.size():  torch.Size([32, 3, 100, 100])\n",
      "forward, x.size() after self.pool(F.relu(self.conv2_bn(self.conv1(x)))):  torch.Size([32, 32, 48, 48])\n",
      "forward, x.size() after self.pool2(F.relu(self.conv2(x))):  torch.Size([32, 64, 16, 16])\n",
      "forward, x.size() after x.view(-1, 64 * 4 * 4 * 16):  torch.Size([32, 16384])\n",
      "forward, x.size() after F.relu(self.fc1(x)):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.dropout(x):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.fc2(x):  torch.Size([32, 1])\n",
      "forward, x.size() after self.sigmoid(x):  torch.Size([32, 1])\n",
      "forward, input x.size():  torch.Size([32, 3, 100, 100])\n",
      "forward, x.size() after self.pool(F.relu(self.conv2_bn(self.conv1(x)))):  torch.Size([32, 32, 48, 48])\n",
      "forward, x.size() after self.pool2(F.relu(self.conv2(x))):  torch.Size([32, 64, 16, 16])\n",
      "forward, x.size() after x.view(-1, 64 * 4 * 4 * 16):  torch.Size([32, 16384])\n",
      "forward, x.size() after F.relu(self.fc1(x)):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.dropout(x):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.fc2(x):  torch.Size([32, 1])\n",
      "forward, x.size() after self.sigmoid(x):  torch.Size([32, 1])\n",
      "forward, input x.size():  torch.Size([32, 3, 100, 100])\n",
      "forward, x.size() after self.pool(F.relu(self.conv2_bn(self.conv1(x)))):  torch.Size([32, 32, 48, 48])\n",
      "forward, x.size() after self.pool2(F.relu(self.conv2(x))):  torch.Size([32, 64, 16, 16])\n",
      "forward, x.size() after x.view(-1, 64 * 4 * 4 * 16):  torch.Size([32, 16384])\n",
      "forward, x.size() after F.relu(self.fc1(x)):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.dropout(x):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.fc2(x):  torch.Size([32, 1])\n",
      "forward, x.size() after self.sigmoid(x):  torch.Size([32, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward, input x.size():  torch.Size([32, 3, 100, 100])\n",
      "forward, x.size() after self.pool(F.relu(self.conv2_bn(self.conv1(x)))):  torch.Size([32, 32, 48, 48])\n",
      "forward, x.size() after self.pool2(F.relu(self.conv2(x))):  torch.Size([32, 64, 16, 16])\n",
      "forward, x.size() after x.view(-1, 64 * 4 * 4 * 16):  torch.Size([32, 16384])\n",
      "forward, x.size() after F.relu(self.fc1(x)):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.dropout(x):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.fc2(x):  torch.Size([32, 1])\n",
      "forward, x.size() after self.sigmoid(x):  torch.Size([32, 1])\n",
      "forward, input x.size():  torch.Size([32, 3, 100, 100])\n",
      "forward, x.size() after self.pool(F.relu(self.conv2_bn(self.conv1(x)))):  torch.Size([32, 32, 48, 48])\n",
      "forward, x.size() after self.pool2(F.relu(self.conv2(x))):  torch.Size([32, 64, 16, 16])\n",
      "forward, x.size() after x.view(-1, 64 * 4 * 4 * 16):  torch.Size([32, 16384])\n",
      "forward, x.size() after F.relu(self.fc1(x)):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.dropout(x):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.fc2(x):  torch.Size([32, 1])\n",
      "forward, x.size() after self.sigmoid(x):  torch.Size([32, 1])\n",
      "forward, input x.size():  torch.Size([32, 3, 100, 100])\n",
      "forward, x.size() after self.pool(F.relu(self.conv2_bn(self.conv1(x)))):  torch.Size([32, 32, 48, 48])\n",
      "forward, x.size() after self.pool2(F.relu(self.conv2(x))):  torch.Size([32, 64, 16, 16])\n",
      "forward, x.size() after x.view(-1, 64 * 4 * 4 * 16):  torch.Size([32, 16384])\n",
      "forward, x.size() after F.relu(self.fc1(x)):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.dropout(x):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.fc2(x):  torch.Size([32, 1])\n",
      "forward, x.size() after self.sigmoid(x):  torch.Size([32, 1])\n",
      "forward, input x.size():  torch.Size([32, 3, 100, 100])\n",
      "forward, x.size() after self.pool(F.relu(self.conv2_bn(self.conv1(x)))):  torch.Size([32, 32, 48, 48])\n",
      "forward, x.size() after self.pool2(F.relu(self.conv2(x))):  torch.Size([32, 64, 16, 16])\n",
      "forward, x.size() after x.view(-1, 64 * 4 * 4 * 16):  torch.Size([32, 16384])\n",
      "forward, x.size() after F.relu(self.fc1(x)):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.dropout(x):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.fc2(x):  torch.Size([32, 1])\n",
      "forward, x.size() after self.sigmoid(x):  torch.Size([32, 1])\n",
      "forward, input x.size():  torch.Size([32, 3, 100, 100])\n",
      "forward, x.size() after self.pool(F.relu(self.conv2_bn(self.conv1(x)))):  torch.Size([32, 32, 48, 48])\n",
      "forward, x.size() after self.pool2(F.relu(self.conv2(x))):  torch.Size([32, 64, 16, 16])\n",
      "forward, x.size() after x.view(-1, 64 * 4 * 4 * 16):  torch.Size([32, 16384])\n",
      "forward, x.size() after F.relu(self.fc1(x)):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.dropout(x):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.fc2(x):  torch.Size([32, 1])\n",
      "forward, x.size() after self.sigmoid(x):  torch.Size([32, 1])\n",
      "forward, input x.size():  torch.Size([32, 3, 100, 100])\n",
      "forward, x.size() after self.pool(F.relu(self.conv2_bn(self.conv1(x)))):  torch.Size([32, 32, 48, 48])\n",
      "forward, x.size() after self.pool2(F.relu(self.conv2(x))):  torch.Size([32, 64, 16, 16])\n",
      "forward, x.size() after x.view(-1, 64 * 4 * 4 * 16):  torch.Size([32, 16384])\n",
      "forward, x.size() after F.relu(self.fc1(x)):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.dropout(x):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.fc2(x):  torch.Size([32, 1])\n",
      "forward, x.size() after self.sigmoid(x):  torch.Size([32, 1])\n",
      "forward, input x.size():  torch.Size([32, 3, 100, 100])\n",
      "forward, x.size() after self.pool(F.relu(self.conv2_bn(self.conv1(x)))):  torch.Size([32, 32, 48, 48])\n",
      "forward, x.size() after self.pool2(F.relu(self.conv2(x))):  torch.Size([32, 64, 16, 16])\n",
      "forward, x.size() after x.view(-1, 64 * 4 * 4 * 16):  torch.Size([32, 16384])\n",
      "forward, x.size() after F.relu(self.fc1(x)):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.dropout(x):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.fc2(x):  torch.Size([32, 1])\n",
      "forward, x.size() after self.sigmoid(x):  torch.Size([32, 1])\n",
      "forward, input x.size():  torch.Size([32, 3, 100, 100])\n",
      "forward, x.size() after self.pool(F.relu(self.conv2_bn(self.conv1(x)))):  torch.Size([32, 32, 48, 48])\n",
      "forward, x.size() after self.pool2(F.relu(self.conv2(x))):  torch.Size([32, 64, 16, 16])\n",
      "forward, x.size() after x.view(-1, 64 * 4 * 4 * 16):  torch.Size([32, 16384])\n",
      "forward, x.size() after F.relu(self.fc1(x)):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.dropout(x):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.fc2(x):  torch.Size([32, 1])\n",
      "forward, x.size() after self.sigmoid(x):  torch.Size([32, 1])\n",
      "forward, input x.size():  torch.Size([32, 3, 100, 100])\n",
      "forward, x.size() after self.pool(F.relu(self.conv2_bn(self.conv1(x)))):  torch.Size([32, 32, 48, 48])\n",
      "forward, x.size() after self.pool2(F.relu(self.conv2(x))):  torch.Size([32, 64, 16, 16])\n",
      "forward, x.size() after x.view(-1, 64 * 4 * 4 * 16):  torch.Size([32, 16384])\n",
      "forward, x.size() after F.relu(self.fc1(x)):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.dropout(x):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.fc2(x):  torch.Size([32, 1])\n",
      "forward, x.size() after self.sigmoid(x):  torch.Size([32, 1])\n",
      "forward, input x.size():  torch.Size([32, 3, 100, 100])\n",
      "forward, x.size() after self.pool(F.relu(self.conv2_bn(self.conv1(x)))):  torch.Size([32, 32, 48, 48])\n",
      "forward, x.size() after self.pool2(F.relu(self.conv2(x))):  torch.Size([32, 64, 16, 16])\n",
      "forward, x.size() after x.view(-1, 64 * 4 * 4 * 16):  torch.Size([32, 16384])\n",
      "forward, x.size() after F.relu(self.fc1(x)):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.dropout(x):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.fc2(x):  torch.Size([32, 1])\n",
      "forward, x.size() after self.sigmoid(x):  torch.Size([32, 1])\n",
      "forward, input x.size():  torch.Size([32, 3, 100, 100])\n",
      "forward, x.size() after self.pool(F.relu(self.conv2_bn(self.conv1(x)))):  torch.Size([32, 32, 48, 48])\n",
      "forward, x.size() after self.pool2(F.relu(self.conv2(x))):  torch.Size([32, 64, 16, 16])\n",
      "forward, x.size() after x.view(-1, 64 * 4 * 4 * 16):  torch.Size([32, 16384])\n",
      "forward, x.size() after F.relu(self.fc1(x)):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.dropout(x):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.fc2(x):  torch.Size([32, 1])\n",
      "forward, x.size() after self.sigmoid(x):  torch.Size([32, 1])\n",
      "forward, input x.size():  torch.Size([32, 3, 100, 100])\n",
      "forward, x.size() after self.pool(F.relu(self.conv2_bn(self.conv1(x)))):  torch.Size([32, 32, 48, 48])\n",
      "forward, x.size() after self.pool2(F.relu(self.conv2(x))):  torch.Size([32, 64, 16, 16])\n",
      "forward, x.size() after x.view(-1, 64 * 4 * 4 * 16):  torch.Size([32, 16384])\n",
      "forward, x.size() after F.relu(self.fc1(x)):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.dropout(x):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.fc2(x):  torch.Size([32, 1])\n",
      "forward, x.size() after self.sigmoid(x):  torch.Size([32, 1])\n",
      "forward, input x.size():  torch.Size([32, 3, 100, 100])\n",
      "forward, x.size() after self.pool(F.relu(self.conv2_bn(self.conv1(x)))):  torch.Size([32, 32, 48, 48])\n",
      "forward, x.size() after self.pool2(F.relu(self.conv2(x))):  torch.Size([32, 64, 16, 16])\n",
      "forward, x.size() after x.view(-1, 64 * 4 * 4 * 16):  torch.Size([32, 16384])\n",
      "forward, x.size() after F.relu(self.fc1(x)):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.dropout(x):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.fc2(x):  torch.Size([32, 1])\n",
      "forward, x.size() after self.sigmoid(x):  torch.Size([32, 1])\n",
      "forward, input x.size():  torch.Size([32, 3, 100, 100])\n",
      "forward, x.size() after self.pool(F.relu(self.conv2_bn(self.conv1(x)))):  torch.Size([32, 32, 48, 48])\n",
      "forward, x.size() after self.pool2(F.relu(self.conv2(x))):  torch.Size([32, 64, 16, 16])\n",
      "forward, x.size() after x.view(-1, 64 * 4 * 4 * 16):  torch.Size([32, 16384])\n",
      "forward, x.size() after F.relu(self.fc1(x)):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.dropout(x):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.fc2(x):  torch.Size([32, 1])\n",
      "forward, x.size() after self.sigmoid(x):  torch.Size([32, 1])\n",
      "forward, input x.size():  torch.Size([32, 3, 100, 100])\n",
      "forward, x.size() after self.pool(F.relu(self.conv2_bn(self.conv1(x)))):  torch.Size([32, 32, 48, 48])\n",
      "forward, x.size() after self.pool2(F.relu(self.conv2(x))):  torch.Size([32, 64, 16, 16])\n",
      "forward, x.size() after x.view(-1, 64 * 4 * 4 * 16):  torch.Size([32, 16384])\n",
      "forward, x.size() after F.relu(self.fc1(x)):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.dropout(x):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.fc2(x):  torch.Size([32, 1])\n",
      "forward, x.size() after self.sigmoid(x):  torch.Size([32, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward, input x.size():  torch.Size([32, 3, 100, 100])\n",
      "forward, x.size() after self.pool(F.relu(self.conv2_bn(self.conv1(x)))):  torch.Size([32, 32, 48, 48])\n",
      "forward, x.size() after self.pool2(F.relu(self.conv2(x))):  torch.Size([32, 64, 16, 16])\n",
      "forward, x.size() after x.view(-1, 64 * 4 * 4 * 16):  torch.Size([32, 16384])\n",
      "forward, x.size() after F.relu(self.fc1(x)):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.dropout(x):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.fc2(x):  torch.Size([32, 1])\n",
      "forward, x.size() after self.sigmoid(x):  torch.Size([32, 1])\n",
      "forward, input x.size():  torch.Size([32, 3, 100, 100])\n",
      "forward, x.size() after self.pool(F.relu(self.conv2_bn(self.conv1(x)))):  torch.Size([32, 32, 48, 48])\n",
      "forward, x.size() after self.pool2(F.relu(self.conv2(x))):  torch.Size([32, 64, 16, 16])\n",
      "forward, x.size() after x.view(-1, 64 * 4 * 4 * 16):  torch.Size([32, 16384])\n",
      "forward, x.size() after F.relu(self.fc1(x)):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.dropout(x):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.fc2(x):  torch.Size([32, 1])\n",
      "forward, x.size() after self.sigmoid(x):  torch.Size([32, 1])\n",
      "forward, input x.size():  torch.Size([32, 3, 100, 100])\n",
      "forward, x.size() after self.pool(F.relu(self.conv2_bn(self.conv1(x)))):  torch.Size([32, 32, 48, 48])\n",
      "forward, x.size() after self.pool2(F.relu(self.conv2(x))):  torch.Size([32, 64, 16, 16])\n",
      "forward, x.size() after x.view(-1, 64 * 4 * 4 * 16):  torch.Size([32, 16384])\n",
      "forward, x.size() after F.relu(self.fc1(x)):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.dropout(x):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.fc2(x):  torch.Size([32, 1])\n",
      "forward, x.size() after self.sigmoid(x):  torch.Size([32, 1])\n",
      "forward, input x.size():  torch.Size([32, 3, 100, 100])\n",
      "forward, x.size() after self.pool(F.relu(self.conv2_bn(self.conv1(x)))):  torch.Size([32, 32, 48, 48])\n",
      "forward, x.size() after self.pool2(F.relu(self.conv2(x))):  torch.Size([32, 64, 16, 16])\n",
      "forward, x.size() after x.view(-1, 64 * 4 * 4 * 16):  torch.Size([32, 16384])\n",
      "forward, x.size() after F.relu(self.fc1(x)):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.dropout(x):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.fc2(x):  torch.Size([32, 1])\n",
      "forward, x.size() after self.sigmoid(x):  torch.Size([32, 1])\n",
      "forward, input x.size():  torch.Size([32, 3, 100, 100])\n",
      "forward, x.size() after self.pool(F.relu(self.conv2_bn(self.conv1(x)))):  torch.Size([32, 32, 48, 48])\n",
      "forward, x.size() after self.pool2(F.relu(self.conv2(x))):  torch.Size([32, 64, 16, 16])\n",
      "forward, x.size() after x.view(-1, 64 * 4 * 4 * 16):  torch.Size([32, 16384])\n",
      "forward, x.size() after F.relu(self.fc1(x)):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.dropout(x):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.fc2(x):  torch.Size([32, 1])\n",
      "forward, x.size() after self.sigmoid(x):  torch.Size([32, 1])\n",
      "forward, input x.size():  torch.Size([32, 3, 100, 100])\n",
      "forward, x.size() after self.pool(F.relu(self.conv2_bn(self.conv1(x)))):  torch.Size([32, 32, 48, 48])\n",
      "forward, x.size() after self.pool2(F.relu(self.conv2(x))):  torch.Size([32, 64, 16, 16])\n",
      "forward, x.size() after x.view(-1, 64 * 4 * 4 * 16):  torch.Size([32, 16384])\n",
      "forward, x.size() after F.relu(self.fc1(x)):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.dropout(x):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.fc2(x):  torch.Size([32, 1])\n",
      "forward, x.size() after self.sigmoid(x):  torch.Size([32, 1])\n",
      "forward, input x.size():  torch.Size([32, 3, 100, 100])\n",
      "forward, x.size() after self.pool(F.relu(self.conv2_bn(self.conv1(x)))):  torch.Size([32, 32, 48, 48])\n",
      "forward, x.size() after self.pool2(F.relu(self.conv2(x))):  torch.Size([32, 64, 16, 16])\n",
      "forward, x.size() after x.view(-1, 64 * 4 * 4 * 16):  torch.Size([32, 16384])\n",
      "forward, x.size() after F.relu(self.fc1(x)):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.dropout(x):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.fc2(x):  torch.Size([32, 1])\n",
      "forward, x.size() after self.sigmoid(x):  torch.Size([32, 1])\n",
      "forward, input x.size():  torch.Size([32, 3, 100, 100])\n",
      "forward, x.size() after self.pool(F.relu(self.conv2_bn(self.conv1(x)))):  torch.Size([32, 32, 48, 48])\n",
      "forward, x.size() after self.pool2(F.relu(self.conv2(x))):  torch.Size([32, 64, 16, 16])\n",
      "forward, x.size() after x.view(-1, 64 * 4 * 4 * 16):  torch.Size([32, 16384])\n",
      "forward, x.size() after F.relu(self.fc1(x)):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.dropout(x):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.fc2(x):  torch.Size([32, 1])\n",
      "forward, x.size() after self.sigmoid(x):  torch.Size([32, 1])\n",
      "forward, input x.size():  torch.Size([32, 3, 100, 100])\n",
      "forward, x.size() after self.pool(F.relu(self.conv2_bn(self.conv1(x)))):  torch.Size([32, 32, 48, 48])\n",
      "forward, x.size() after self.pool2(F.relu(self.conv2(x))):  torch.Size([32, 64, 16, 16])\n",
      "forward, x.size() after x.view(-1, 64 * 4 * 4 * 16):  torch.Size([32, 16384])\n",
      "forward, x.size() after F.relu(self.fc1(x)):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.dropout(x):  torch.Size([32, 1024])\n",
      "forward, x.size() after self.fc2(x):  torch.Size([32, 1])\n",
      "forward, x.size() after self.sigmoid(x):  torch.Size([32, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-2:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/uldo/work/kaggle/competitions/Humpback_Whale_Identification/code/load_data.py\", line 242, in __getitem__\n",
      "    image = Image.open(path_to_image_file).convert('RGB')\n",
      "  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/PIL/Image.py\", line 892, in convert\n",
      "    self.load()\n",
      "  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/PIL/ImageFile.py\", line 235, in load\n",
      "    n, err_code = decoder.decode(b)\n",
      "KeyboardInterrupt\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2961, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-44-833e1aeb431c>\", line 7, in <module>\n",
      "    optimizer\n",
      "  File \"<ipython-input-18-b8db493c24ea>\", line 17, in train_model\n",
      "    train_loss, train_accuracy = one_epoch_train(model, train_loader, criterion, optimizer)\n",
      "  File \"<ipython-input-14-34a362bcb7eb>\", line 7, in one_epoch_train\n",
      "    for i, data_batch in enumerate(data_loader, 0):\n",
      "  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 330, in __next__\n",
      "    idx, batch = self._get_batch()\n",
      "  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 309, in _get_batch\n",
      "    return self.data_queue.get()\n",
      "  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 1863, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 311, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 345, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/inspect.py\", line 1483, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/inspect.py\", line 1441, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 227, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 50430) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "train_rezult_metrics = train_model(\n",
    "    num_of_epoch,\n",
    "    hwi_conv_neural_net,\n",
    "    dataset_loaders,\n",
    "    dataset_sizes,\n",
    "    criterion,\n",
    "    optimizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses, train_accuracies, validation_losses, validation_accuracies = train_rezult_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(len(train_losses)), train_losses, label='train')\n",
    "plt.plot(np.arange(len(validation_losses)), validation_losses, label='validation')\n",
    "plt.legend()\n",
    "plt.title(\"loss by epoch\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(np.arange(len(train_accuracies)), train_accuracies, label='train')\n",
    "plt.plot(np.arange(len(validation_accuracies)), validation_accuracies, label='validation')\n",
    "plt.legend()\n",
    "plt.title(\"accuracy by epoch\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
